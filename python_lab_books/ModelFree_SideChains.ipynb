{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import pi, r_\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "from matplotlib import rc\n",
    "from scipy import optimize\n",
    "from scipy.optimize import minimize\n",
    "import re\n",
    "import sys\n",
    "import subprocess\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'size': 16}\n",
    "rc('font', **font)\n",
    "\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams[\"lines.linewidth\"]=2\n",
    "\n",
    "plotting=True # plots should be created ?\n",
    "subplots=True\n",
    "pico=1.*10**(-12) # picoseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file with QUADRIC analysis of the protein backbone --> has to be done before methyl analysis\n",
    "\n",
    "inputpath = \".\"\n",
    "variant='CI2_WT' \n",
    "tumbling = \"iso\" # iso/ani\n",
    "\n",
    "outputpath = inputpath+\"/\"+variant+\"/\"+tumbling\n",
    "\n",
    "## Creat output folder\n",
    "COMMAND = f\"mkdir -p {variant}/{tumbling}\"\n",
    "subprocess.call(COMMAND, shell=True)\n",
    "\n",
    "# Read in input files\n",
    "tumbling_file=inputpath+\"/analysis_\"+tumbling+\"_\"+variant\n",
    "inputfile_times=inputpath+\"/\"+variant+\"_sch_times.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfields=2 # 600, 750 MHz\n",
    "nrates=4 # R1, R2, R3, R4\n",
    "nmodels=2 # LS2, LS3\n",
    "njws=3 # Jomega0, Jomega_D, Jomega_2D \n",
    "\n",
    "# Larmor frquency of deuterium\n",
    "omega_D_field1=2.*pi*92.1298227037992*1000000 # Hr @600 MHz\n",
    "omega_D_field2=2.*pi*115.138869111022*1000000 # Hz @750 MHz\n",
    "# frequencies of spectral density used for the fit / usually frequencies measured in NMR\n",
    "\n",
    "# create array with five frequences  \n",
    "measuredfreq_field1=np.array([i*omega_D_field1 for i in [0,1,2]])\n",
    "measuredfreq_field2=np.array([i*omega_D_field2 for i in [0,1,2]])\n",
    "\n",
    "measuredfreq = np.array([measuredfreq_field1[0], measuredfreq_field2[0],measuredfreq_field1[1], measuredfreq_field2[1],\n",
    "               measuredfreq_field1[2], measuredfreq_field2[2]])\n",
    "\n",
    "frequency = np.linspace(0, 2*10**9, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to calculate methyl relaxation rates from spectral density points\n",
    "def R1(x,y,z):\n",
    "    return 3./16.*pre**2*(0*x+ 1*y+4*z)\n",
    "def R2(x,y,z):\n",
    "    return 1./32.*pre**2*(9*x+15*y+6*z)\n",
    "def R3(x,y,z):                            \n",
    "    return 3./16.*pre**2*(0*x+ 3*y+0*z)\n",
    "def R4(x,y,z):\n",
    "    return 3./16.*pre**2*(0*x+ 1*y+2*z)\n",
    "\n",
    "# functios to calculate spectral density points from methyl relaxation rates\n",
    "\n",
    "pre=2*np.pi*167000 # prefactor based on physical constants\n",
    "A = 3./16.*pre**2 # prefactor A\n",
    "B = 1./32.*pre**2 # prefactor B\n",
    "\n",
    "def J_omega_D(R1,R2,R3):\n",
    "    return R3/(3*A) - R1*0 - R2*0\n",
    "\n",
    "def J_2omega_D(R1,R2,R3):\n",
    "    return (R1/A - R3/(3*A))/4 - R2*0\n",
    "def J_2omega_D_b(R2,R3,R4):\n",
    "    return (R4/A - R3/(3*A))/2 - R2*0  \n",
    "\n",
    "def J_0(R1,R2,R3):\n",
    "    return ( R2/B - 5*R3/A - 1.5*R1/A + 0.5*R3/A ) /9\n",
    "def J_0_b(R2,R3,R4):\n",
    "    return ( R2/B - 5*R3/A - 3*R4/A + R3/A ) /9\n",
    "\n",
    "# calculate Akaike information criterion\n",
    "def CHI2(Rmodel,Rnmr,Rerror):\n",
    "    #print (Rmodel,Rnmr,Rerror)\n",
    "    return sum([((Rmodel[i]-Rnmr[i])/Rerror[i])**2 for i in [0,1,2]])\n",
    "\n",
    "# indices of strings for output file\n",
    "indices=[\"R1spec_field1\",\"R2spec_field1\",\"R3spec_field1\",\"R1spec_field2\",\"R2spec_field2\",\"R3spec_field2\", \n",
    "         \"SLS2\",\"taufLS2\",\"R1LS2_field1\",\"R2LS2_field1\",\"R3LS2_field1\",\"R1LS2_field2\",\"R2LS2_field2\",\"R3LS2_field2\",\n",
    "         \"Jw1LS2_field1\",\"Jw2LS2_field1\",\"Jw3LS2_field1\",\"Jw1LS2_field2\",\"Jw2LS2_field2\",\"Jw3LS2_field2\",\n",
    "         \"SLS3\",\"taurLS3\",\"taufLS3\",\"R1LS3_field1\",\"R2LS3_field1\",\"R3LS3_field1\",\"R1LS3_field2\",\"R2LS3_field2\",\"R3LS3_field2\",\n",
    "         \"Jw1LS3_field1\",\"Jw2LS3_field1\",\"Jw3LS3_field1\",\"Jw1LS3_field2\",\"Jw2LS3_field2\",\"Jw3LS3_field2\",\"AIC_LS2\",\"AIC_LS3\"]\n",
    "\n",
    "# create empty dataframe of order parameter\n",
    "order=pd.DataFrame()\n",
    "\n",
    "relax_times_exp = pd.read_csv(inputfile_times, sep=\",\", index_col=[0])\n",
    "relax_times_exp_size= np.size(relax_times_exp,0)\n",
    "\n",
    "def LS2ns_MC(x,p11,p22):\n",
    "    return 2./5.*(1./9.*p11*taumps/(1.+(x*taumps)**2)+(1.-1./9.*p11)*taumps*p22/(taumps+p22+(x*taumps*p22)**2/(taumps+p22))) # Lipari-Szabo function\n",
    "   \n",
    "def LS3ns_MC(x,p11,p22,p33):    \n",
    "    return 2./5.*(1./9.*p11*p33/(1.+(x*p33)**2)+(1.-1./9.*p11)*p33*p22/(p33+p22+(x*p33*p22)**2/(p33+p22))) # Lipari-Szabo function\n",
    "\n",
    "def ERR_STDV(All,A,B,C,D,E,F,G,H):\n",
    "    return math.sqrt(((A-All)**2+(B-All)**2+(C-All)**2+(D-All)**2+(E-All)**2+(F-All)**2+(G-All)**2+(H-All)**2)/7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exp_pre_rates (relax_times_exp):\n",
    "    \n",
    "    # it is assumed that input \"relax_times_exp\" contains methyl relaxation times (T1-T4) in miliseconds (ms)  \n",
    "    # and corresponding uncertainties (errors) in a format: \n",
    "    # columns: T1, T1_err, T2, T2 err, etc.\n",
    "    # rows: individual methyl groups\n",
    "    \n",
    "    times=relax_times_exp.iloc[i][::2].values # in ms\n",
    "    errors = relax_times_exp.iloc[i][1::2].values # in ms\n",
    "    \n",
    "    R_exp = 1/(times*0.001) \n",
    "    R_err_exp = np.divide(errors/0.001, times**2) \n",
    "    \n",
    "    return R_exp, R_err_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "strR1 = \"\\t(((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+4*Jomegas_pre[3]))-Rates[0])/Rates_err[0])**2+\\\\\\n\"\n",
    "strR2 = \"\\t(((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[1]+6*Jomegas_pre[3]))-Rates[1])/Rates_err[1])**2+\\\\\\n\" \n",
    "strR3 = \"\\t(((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[1]+0*Jomegas_pre[3]))-Rates[2])/Rates_err[2])**2+\\\\\\n\" \n",
    "strR4 = \"\\t(((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+2*Jomegas_pre[3]))-Rates[3])/Rates_err[3])**2+\\\\\\n\" \n",
    "strR5 = \"\\t(((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+4*Jomegas_pre[4]))-Rates[4])/Rates_err[4])**2+\\\\\\n\" \n",
    "strR6 = \"\\t(((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[2]+6*Jomegas_pre[4]))-Rates[5])/Rates_err[5])**2+\\\\\\n\" \n",
    "strR7 = \"\\t(((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[2]+0*Jomegas_pre[4]))-Rates[6])/Rates_err[6])**2+\\\\\\n\" \n",
    "strR8 = \"\\t(((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+2*Jomegas_pre[4]))-Rates[7])/Rates_err[7])**2\\n\" \n",
    "\n",
    "#str_plus = \" + \\\\\\n\"\n",
    "\n",
    "func_top = \"def Chi2_Jpre_all (Jomegas_pre,Rates,Rates_err):\\n\"\n",
    "return_stat = \"\\treturn \\\\\\n\"\n",
    "\n",
    "#f = open(f\"./chi2_func.py\", 'w')\n",
    "# print(func_top,return_sta,\n",
    "#       strR1,str_plus,strR2,str_plus,strR3,str_plus,strR4,str_plus,\\\n",
    "#       strR5,str_plus,strR6,str_plus,strR7,str_plus,strR8,file=f)\n",
    "\n",
    "for x in range(1,nrates*nfields+1):\n",
    "    if x == nrates*nfields:\n",
    "        exec(f\"strR{x-1} = strR{x-1}[:-3]\")\n",
    "    \n",
    "    exec(f\"temp = strR{x}\")\n",
    "    exec(f\"strR{x} = \\\"\\\"\")\n",
    "    f = open(f\"./chi2_func_noR{x}.py\", 'w')\n",
    "    print(func_top,return_stat,strR1,strR2,strR3,strR4,strR5,strR6,strR7,strR8,file=f)\n",
    "    f.close()\n",
    "    exec(f\"strR{x} = temp\")\n",
    "    #from chi2_func import Chi2_Jpre_all\n",
    "    #delete file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all Chi2_Jpre functions should be stated explicitly and separately to be minimized;\n",
    "# equations corresponding to the guessed rates should be explicitly stated through Jomegas_pre[x],\n",
    "# since each Jomegas_pre[x] is going to be minimized\n",
    "\n",
    "\n",
    "# def Chi2_Jpre_all (Jomegas_pre,Rates,Rates_err): # x = J_0, y = J_D, z = J_2D\n",
    "#     return  \\\n",
    "#             (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+4*Jomegas_pre[3]))-Rates[0])/Rates_err[0])**2 + \\\n",
    "#             (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[1]+6*Jomegas_pre[3]))-Rates[1])/Rates_err[1])**2 + \\\n",
    "#             (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[1]+0*Jomegas_pre[3]))-Rates[2])/Rates_err[2])**2 + \\\n",
    "#             (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+2*Jomegas_pre[3]))-Rates[3])/Rates_err[3])**2 + \\\n",
    "#             (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+4*Jomegas_pre[4]))-Rates[4])/Rates_err[4])**2 + \\\n",
    "#             (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[2]+6*Jomegas_pre[4]))-Rates[5])/Rates_err[5])**2 + \\\n",
    "#             (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[2]+0*Jomegas_pre[4]))-Rates[6])/Rates_err[6])**2 + \\\n",
    "#             (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+2*Jomegas_pre[4]))-Rates[7])/Rates_err[7])**2 \n",
    "\n",
    "\n",
    "def Chi2_Jpre_noR1_field1 (Jomegas_pre,Rates,Rates_err): # x = J_0, y = J_D, z = J_2D\n",
    "    return  \\\n",
    "            (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[1]+6*Jomegas_pre[3]))-Rates[1])/Rates_err[1])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[1]+0*Jomegas_pre[3]))-Rates[2])/Rates_err[2])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+2*Jomegas_pre[3]))-Rates[3])/Rates_err[3])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+4*Jomegas_pre[4]))-Rates[4])/Rates_err[4])**2 + \\\n",
    "            (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[2]+6*Jomegas_pre[4]))-Rates[5])/Rates_err[5])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[2]+0*Jomegas_pre[4]))-Rates[6])/Rates_err[6])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+2*Jomegas_pre[4]))-Rates[7])/Rates_err[7])**2\n",
    "\n",
    "def Chi2_Jpre_noR2_field1 (Jomegas_pre,Rates,Rates_err): # x = J_0, y = J_D, z = J_2D\n",
    "    return  \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+4*Jomegas_pre[3]))-Rates[0])/Rates_err[0])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[1]+0*Jomegas_pre[3]))-Rates[2])/Rates_err[2])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+2*Jomegas_pre[3]))-Rates[3])/Rates_err[3])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+4*Jomegas_pre[4]))-Rates[4])/Rates_err[4])**2 + \\\n",
    "            (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[2]+6*Jomegas_pre[4]))-Rates[5])/Rates_err[5])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[2]+0*Jomegas_pre[4]))-Rates[6])/Rates_err[6])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+2*Jomegas_pre[4]))-Rates[7])/Rates_err[7])**2\n",
    "\n",
    "def Chi2_Jpre_noR3_field1 (Jomegas_pre,Rates,Rates_err): # x = J_0, y = J_D, z = J_2D\n",
    "    return  \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+4*Jomegas_pre[3]))-Rates[0])/Rates_err[0])**2 + \\\n",
    "            (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[1]+6*Jomegas_pre[3]))-Rates[1])/Rates_err[1])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+2*Jomegas_pre[3]))-Rates[3])/Rates_err[3])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+4*Jomegas_pre[4]))-Rates[4])/Rates_err[4])**2 + \\\n",
    "            (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[2]+6*Jomegas_pre[4]))-Rates[5])/Rates_err[5])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[2]+0*Jomegas_pre[4]))-Rates[6])/Rates_err[6])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+2*Jomegas_pre[4]))-Rates[7])/Rates_err[7])**2\n",
    "\n",
    "def Chi2_Jpre_noR4_field1 (Jomegas_pre,Rates,Rates_err): # x = J_0, y = J_D, z = J_2D\n",
    "    return  \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+4*Jomegas_pre[3]))-Rates[0])/Rates_err[0])**2 + \\\n",
    "            (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[1]+6*Jomegas_pre[3]))-Rates[1])/Rates_err[1])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[1]+0*Jomegas_pre[3]))-Rates[2])/Rates_err[2])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+4*Jomegas_pre[4]))-Rates[4])/Rates_err[4])**2 + \\\n",
    "            (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[2]+6*Jomegas_pre[4]))-Rates[5])/Rates_err[5])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[2]+0*Jomegas_pre[4]))-Rates[6])/Rates_err[6])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+2*Jomegas_pre[4]))-Rates[7])/Rates_err[7])**2\n",
    "\n",
    "def Chi2_Jpre_noR1_field2 (Jomegas_pre,Rates,Rates_err): # x = J_0, y = J_D, z = J_2D\n",
    "    return  \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+4*Jomegas_pre[3]))-Rates[0])/Rates_err[0])**2 + \\\n",
    "            (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[1]+6*Jomegas_pre[3]))-Rates[1])/Rates_err[1])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[1]+0*Jomegas_pre[3]))-Rates[2])/Rates_err[2])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+2*Jomegas_pre[3]))-Rates[3])/Rates_err[3])**2 + \\\n",
    "            (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[2]+6*Jomegas_pre[4]))-Rates[5])/Rates_err[5])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[2]+0*Jomegas_pre[4]))-Rates[6])/Rates_err[6])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+2*Jomegas_pre[4]))-Rates[7])/Rates_err[7])**2\n",
    "\n",
    "def Chi2_Jpre_noR2_field2 (Jomegas_pre,Rates,Rates_err): # x = J_0, y = J_D, z = J_2D\n",
    "    return  \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+4*Jomegas_pre[3]))-Rates[0])/Rates_err[0])**2 + \\\n",
    "            (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[1]+6*Jomegas_pre[3]))-Rates[1])/Rates_err[1])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[1]+0*Jomegas_pre[3]))-Rates[2])/Rates_err[2])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+2*Jomegas_pre[3]))-Rates[3])/Rates_err[3])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+4*Jomegas_pre[4]))-Rates[4])/Rates_err[4])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[2]+0*Jomegas_pre[4]))-Rates[6])/Rates_err[6])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+2*Jomegas_pre[4]))-Rates[7])/Rates_err[7])**2\n",
    "\n",
    "def Chi2_Jpre_noR3_field2 (Jomegas_pre,Rates,Rates_err): # x = J_0, y = J_D, z = J_2D\n",
    "    return  \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+4*Jomegas_pre[3]))-Rates[0])/Rates_err[0])**2 + \\\n",
    "            (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[1]+6*Jomegas_pre[3]))-Rates[1])/Rates_err[1])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[1]+0*Jomegas_pre[3]))-Rates[2])/Rates_err[2])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+2*Jomegas_pre[3]))-Rates[3])/Rates_err[3])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+4*Jomegas_pre[4]))-Rates[4])/Rates_err[4])**2 + \\\n",
    "            (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[2]+6*Jomegas_pre[4]))-Rates[5])/Rates_err[5])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+2*Jomegas_pre[4]))-Rates[7])/Rates_err[7])**2\n",
    "\n",
    "def Chi2_Jpre_noR4_field2 (Jomegas_pre,Rates,Rates_err): # x = J_0, y = J_D, z = J_2D\n",
    "    return  \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+4*Jomegas_pre[3]))-Rates[0])/Rates_err[0])**2 + \\\n",
    "            (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[1]+6*Jomegas_pre[3]))-Rates[1])/Rates_err[1])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[1]+0*Jomegas_pre[3]))-Rates[2])/Rates_err[2])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+2*Jomegas_pre[3]))-Rates[3])/Rates_err[3])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+4*Jomegas_pre[4]))-Rates[4])/Rates_err[4])**2 + \\\n",
    "            (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[2]+6*Jomegas_pre[4]))-Rates[5])/Rates_err[5])**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[2]+0*Jomegas_pre[4]))-Rates[6])/Rates_err[6])**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_Chi2_Jpre(Jomegas_pre,Chi2_Jpre):\n",
    "    \n",
    "    positive = { 'type': 'ineq', 'fun' : lambda x: np.array(x) }\n",
    "    opt = { 'maxiter': 500 , 'disp': False}\n",
    "    \n",
    "    result = optimize.minimize( Chi2_Jpre, Jomegas_pre,args=(Rates,Rates_err), jac = False, constraints = positive, method = 'SLSQP', options = opt )     \n",
    "    JomegaD = np.array([result.x[0], result.x[1], result.x[2], result.x[3], result.x[4]])/pre**2\n",
    "    \n",
    "    return result, JomegaD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(f\"./{variant}_out.txt\", 'w')\n",
    "\n",
    "methID_dict = {\"Ala\":\"ALA\", \"Ile\":\"ILE\", \"Leu\":\"LEU\", \"Met\":\"MET\", \"Thr\":\"THR\", \"Val\":\"VAL\",\n",
    "               \"Cb\":\"-CB\", \"Hb\":\"HB\", \"Cg1\":\"-CG1\",\"Cg2\":\"-CG2\", \"Hg1\":\"HG1\",\"Hg2\":\"HG2\",\"Cd1\":\"-CD1\", \"Hd1\":\"HD1\",\n",
    "               \"Cd2\":\"-CD2\", \"Hd2\":\"HD2\", \"Ce\":\"-CE\", \"He\":\"HE\"}\n",
    "    \n",
    "# Run a loop for all methyl groups:\n",
    "\n",
    "fig1, axes1 = plt.subplots(nrows = round(relax_times_exp.shape[0]/2), ncols = 2, figsize = (11, 105))\n",
    "\n",
    "j=0\n",
    "for i, ax in enumerate(axes1.flatten()):\n",
    "\n",
    "    # 1. get experimental rates from the user input\n",
    "    \n",
    "    Rates, Rates_err = get_exp_pre_rates(relax_times_exp)    \n",
    "    \n",
    "    Rates1to3 = np.array([Rates[0],Rates[1],Rates[2],Rates[4],Rates[5],Rates[6]])\n",
    "    Rates_err1to3 = np.array([Rates_err[0],Rates_err[1],Rates_err[2],Rates_err[4],Rates_err[5],Rates_err[6]])\n",
    "  \n",
    "    # state all the rates explicitly to be further used during minimization\n",
    "    \n",
    "    v_count=0\n",
    "    for field in range(1,nfields+1):\n",
    "        for rate in range(1,nrates+1):\n",
    "            exec(f\"R{rate}_exp_field{field} = Rates[{v_count}]\") \n",
    "            exec(f\"R{rate}_err_exp_field{field} = Rates_err[{v_count}]\") \n",
    "            v_count+=1;\n",
    "            \n",
    "      \n",
    "    # 2. calculate experimental Jomegas based on the experimental rates\n",
    "\n",
    "    Jzero_field1=J_0(Rates[0],Rates[1],Rates[2]) \n",
    "    Jzero_field2=J_0(Rates[4],Rates[5],Rates[6]) # J_0(R1,R2,R3)\n",
    "\n",
    "    Jzero_field1b=J_0_b(Rates[1],Rates[2],Rates[3]) \n",
    "    Jzero_field2b=J_0_b(Rates[5],Rates[6],Rates[7]) # J_0_b(R2,R3,R4)\n",
    "\n",
    "    Jw_D_field1=J_omega_D(Rates[0],Rates[1],Rates[2]) \n",
    "    Jw_D_field2=J_omega_D(Rates[4],Rates[5],Rates[6]) # J_omega_D(R1,R2,R3)\n",
    "    \n",
    "    J2w_D_field1=J_2omega_D(Rates[0],Rates[1],Rates[2]) \n",
    "    J2w_D_field2=J_2omega_D(Rates[4],Rates[5],Rates[6]) # J_2omega_D(R1,R2,R3)\n",
    "\n",
    "    J2w_D_field1b=J_2omega_D_b(Rates[1],Rates[2],Rates[3]) \n",
    "    J2w_D_field2b=J_2omega_D_b(Rates[5],Rates[6],Rates[7]) # J_2omega_D_b(R2,R3,R4)\n",
    "    \n",
    "\n",
    "    # 3. MINIMIZATION USING CHI^2 FUNCTION Chi2_Jpre\n",
    "    ## DOES NOT WORK WITH LOW NUMBERS (10^-12). CONVERTED TO PICOSECONDS with pre**2\n",
    "\n",
    "    measuredfreq = np.array([measuredfreq_field1[0],measuredfreq_field1[1], measuredfreq_field2[1], measuredfreq_field1[2], measuredfreq_field2[2]])\n",
    "    Jomegas_pre = np.array([Jzero_field1, Jw_D_field1, Jw_D_field2, J2w_D_field1, J2w_D_field2])*pre**2  # initial guess of Jomegas (x, y, z)\n",
    "    \n",
    "    result_all,JomegaD = use_Chi2_Jpre(Jomegas_pre,Chi2_Jpre_all)\n",
    "    \n",
    "    for field in range(1,nfields+1):\n",
    "        for rate in range(1,nrates+1):\n",
    "            exec(f\"result_noR{rate}_field{field},JomegaD_noR{rate}_field{field} = use_Chi2_Jpre(Jomegas_pre,Chi2_Jpre_noR{rate}_field{field})\")\n",
    "            \n",
    "    # 4. Identify the current methyl group and it's tumbling time\n",
    "     \n",
    "    methID = relax_times_exp.index[j] \n",
    "    \n",
    "    match = re.search('(\\d+)(\\w{3})(\\w+)_\\d+\\w{3}(\\w+)', methID)\n",
    "    resN = match.group(1) if match else None\n",
    "    resName = match.group(2) if match else None\n",
    "    carbon = match.group(3) if match else None\n",
    "    hydrogen = match.group(4) if match else None\n",
    "    \n",
    "    methIDnew= \" %s%s-%s%s\" % (resName, resN, carbon, hydrogen)\n",
    "    \n",
    "    meth3ID = str(methID_dict[match.group(2)] + match.group(1) + methID_dict[match.group(3)] + methID_dict[match.group(4)])\n",
    "    if resName==\"Ile\" and carbon==\"Cd1\":\n",
    "        meth3ID=meth3ID.replace(\"-CD1HD1\",\"-CDHD\")\n",
    "        \n",
    "                \n",
    "    with open(tumbling_file) as origin_file: # extract tumbling time from external tumbling\n",
    "        for line in origin_file:\n",
    "            match = re.search('(\\d+\\.\\d+)\\s*\\t*\\[(\\w{3}\\d+\\-\\w+\\d*\\w+\\d*)\\]', line) \n",
    "            methylID = match.group(2) if match else None\n",
    "            if methylID:\n",
    "                line = match.group(1) if match else None\n",
    "                taum=float(line)*1000*pico\n",
    "\n",
    "    # 5. Fit the experimental JomegaD values with LS2 or LS3 analytical functions        \n",
    "                \n",
    "    ##LS2 fit\n",
    "    \n",
    "    LS2 = lambda p,x: 2./5.*(1./9.*p[0]*taum/(1.+(x*taum)**2)+(1.-1./9.*p[0])*taum*p[1]/(taum+p[1]+(x*taum*p[1])**2/(taum+p[1]))) # Lipari-Szabo function\n",
    "    errLS2func = lambda p, x, y: LS2(p, x) - y # Distance to the target function\n",
    "    taumps=taum/pico\n",
    "    p02 = [0.5, 50] # Initial guess for the parameters\n",
    "    bounds2_min = [0.,0.]\n",
    "    bounds2_max = [1.,taumps]\n",
    "    bounds2 = [bounds2_min, bounds2_max]\n",
    "    LS2ns = lambda p,x: 2./5.*(1./9.*p[0]*taumps/(1.+(x*taumps)**2)+(1.-1./9.*p[0])*taumps*p[1]/(taumps+p[1]+(x*taumps*p[1])**2/(taumps+p[1]))) # Lipari-Szabo function in ns\n",
    "    errLS2nsfunc = lambda p, x, y: LS2ns(p, x) - y # Distance to the target function\n",
    "    p2 = optimize.least_squares(errLS2nsfunc, p02, bounds=bounds2, args=(measuredfreq*pico, JomegaD/pico)) # fit with LS2 function\n",
    "    p2x=np.array([float(p2.x[0]), float(p2.x[1]*pico)])\n",
    "\n",
    "    ##LS3 fit\n",
    "\n",
    "    LS3 = lambda p,x: 2./5.*(1./9.*p[0]*p[2]/(1.+(x*p[2])**2)+(1.-1./9.*p[0])*p[2]*p[1]/(p[2]+p[1]+(x*p[2]*p[1])**2/(p[2]+p[1]))) # Lipari-Szabo function\n",
    "    errLS3func = lambda p, x, y: LS2(p, x) - y # Distance to the target function\n",
    "    p03 = [0.5, 100, 5000] # Initial guess for the parameters\n",
    "    bounds3_min = [0.,0., 1000.]\n",
    "    bounds3_max = [1.,500,10000]\n",
    "    bounds3 = [bounds3_min, bounds3_max]\n",
    "    LS3ns = lambda p,x: 2./5.*(1./9.*p[0]*p[2]/(1.+(x*p[2])**2)+(1.-1./9.*p[0])*p[2]*p[1]/(p[2]+p[1]+(x*p[2]*p[1])**2/(p[2]+p[1]))) # Lipari-Szabo function\n",
    "    errLS3nsfunc = lambda p, x, y: LS3ns(p, x) - y # Distance to the target function\n",
    "    p3 = optimize.least_squares(errLS3nsfunc, p03, bounds=bounds3, args=(measuredfreq*pico, JomegaD/pico)) # fit with LS3 function\n",
    "    p3x=np.array([float(p3.x[0]), float(p3.x[1]*pico), float(p3.x[2]*pico)])\n",
    "\n",
    "    # 6. calculation of the (anlytical) relaxation rates \n",
    "    # based on the minimized JomegaD with chi2 (against experimental data)\n",
    "    \n",
    "    for field in range(1,nfields+1):\n",
    "        for rate in range(1,nrates+1):\n",
    "            exec(f\"rate{rate}_field{field}=R{rate}(JomegaD[0],JomegaD[1],JomegaD[3])\")  \n",
    "    \n",
    "     \n",
    "    # 7. calculation of spectral densities  at measured frequencies for LS2/LS3\n",
    "    # Since R4 is obsolet, it is not required\n",
    "                \n",
    "    \n",
    "    Jw_LS2 = LS2(p2x,measuredfreq)\n",
    "    Jw_LS3 = LS3(p3x,measuredfreq)\n",
    "    \n",
    "    index1_vec = [0,1,3,0,2,4] # rates order in Jw_LS2/Jw_LS3 \n",
    "    index1=0\n",
    "\n",
    "    for field in range(1,nfields+1):\n",
    "        for jw in range(1,njws+1):\n",
    "                exec(f\"Jw{jw}LS2_field{field}=Jw_LS2[{index1_vec[index1]}]\")\n",
    "                exec(f\"Jw{jw}LS3_field{field}=Jw_LS3[{index1_vec[index1]}]\")\n",
    "                index1+=1\n",
    "    \n",
    "    # 8. rates from LS2/LS3\n",
    "    ratesLS2=[]\n",
    "    ratesLS3=[]\n",
    "    for model in range(2,nmodels+2): # LS2, LS3\n",
    "        for field in range(1,nfields+1):\n",
    "            for rate in range(1,nrates): # no R4\n",
    "                    exec(f\"rate{rate}LS{model}_field{field}=R{rate}(Jw1LS{model}_field{field},Jw2LS{model}_field{field},Jw3LS{model}_field{field})\") \n",
    "                    exec(f\"ratesLS{model}.append(rate{rate}LS{model}_field{field})\")\n",
    "                        \n",
    "    # 9. Use rates to find if LS2 or LS3 provides better fit (with AIC)\n",
    "    \n",
    "\n",
    "    AIC_LS2 = CHI2(ratesLS2,Rates1to3,Rates_err1to3) + 2*2 # CHI2(Rmodel,Rnmr,Rerror)\n",
    "    AIC_LS3 = CHI2(ratesLS3,Rates1to3,Rates_err1to3) + 3*2 # CHI2(Rmodel,Rnmr,Rerror)\n",
    "    \n",
    "    # 10. error estimation for the Jomega values\n",
    "    # based on comparison of chi2 function (experiment vs fit) condidering all Jw's or excluding one of them\n",
    "    # and taking stdv between all the combinations\n",
    "    \n",
    "    Jw0_ERR_STDV = ERR_STDV(result_all.x[0],result_noR1_field1.x[0],result_noR2_field1.x[0],result_noR3_field1.x[0],result_noR4_field1.x[0],result_noR1_field2.x[0],result_noR2_field2.x[0],result_noR3_field2.x[0],result_noR4_field2.x[0])\n",
    "    JwD_field1_ERR_STDV = ERR_STDV(result_all.x[1],result_noR1_field1.x[1],result_noR2_field1.x[1],result_noR3_field1.x[1],result_noR4_field1.x[1],result_noR1_field2.x[1],result_noR2_field2.x[1],result_noR3_field2.x[1],result_noR4_field2.x[1])\n",
    "    JwD2_field1_ERR_STDV = ERR_STDV(result_all.x[2],result_noR1_field1.x[2],result_noR2_field1.x[2],result_noR3_field1.x[2],result_noR4_field1.x[2],result_noR1_field2.x[2],result_noR2_field2.x[2],result_noR3_field2.x[2],result_noR4_field2.x[2])\n",
    "    JwD_field2_ERR_STDV = ERR_STDV(result_all.x[3],result_noR1_field1.x[3],result_noR2_field1.x[3],result_noR3_field1.x[3],result_noR4_field1.x[3],result_noR1_field2.x[3],result_noR2_field2.x[3],result_noR3_field2.x[3],result_noR4_field2.x[3])\n",
    "    JwD2_field2_ERR_STDV = ERR_STDV(result_all.x[4],result_noR1_field1.x[4],result_noR2_field1.x[4],result_noR3_field1.x[4],result_noR4_field1.x[4],result_noR1_field2.x[4],result_noR2_field2.x[4],result_noR3_field2.x[4],result_noR4_field2.x[4])\n",
    "    \n",
    "    err_Jws = np.array([Jw0_ERR_STDV,JwD_field1_ERR_STDV,JwD2_field1_ERR_STDV,JwD_field2_ERR_STDV,JwD2_field2_ERR_STDV]) \n",
    "    \n",
    "    # 11. ###### MONTE CARLO SIMULATION ##########\n",
    "    ### TO DEFINE PARAMETERS' (S2, tauf) ERRORS    \n",
    "    \n",
    "    if AIC_LS2<=AIC_LS3: \n",
    "        LSns_MC = LS2ns_MC\n",
    "        vGuess = [0.5,50]\n",
    "    else:\n",
    "        LSns_MC = LS3ns_MC\n",
    "        vGuess = [0.5,100,5000]\n",
    "        \n",
    "    sError = err_Jws # error based on using all Jw's vs excluding obsolete Jw's. This way the error is based only on the variations in the experimental data\n",
    "    nTrials = 4000\n",
    "    aFitPars = np.array([])\n",
    "    \n",
    "    \n",
    "    for iTrial in range(nTrials):\n",
    "        xTrial = measuredfreq*pico\n",
    "        yGen = JomegaD/pico\n",
    "        yTrial = yGen + np.random.normal(scale=sError,size=np.size(yGen))\n",
    "\n",
    "        # We use a try/except clause to catch pathologies\n",
    "        try:                \n",
    "                vTrial, aCova = optimize.curve_fit(LSns_MC,xTrial,yTrial,vGuess)\n",
    "\n",
    "        except:\n",
    "\n",
    "            continue  # This moves us to the next loop without stacking.\n",
    "            \n",
    "        #here follows the syntax for stacking the trial onto the running sample:\n",
    "        if np.size(aFitPars) < 1:\n",
    "            aFitPars=np.copy(vTrial)\n",
    "        else:\n",
    "            aFitPars = np.vstack(( aFitPars, vTrial ))\n",
    "        \n",
    "    S2_tauf_MC_std=np.array([float(np.median(aFitPars[:,0])), float(np.std(aFitPars[:,0])), \\\n",
    "                             float(np.median(aFitPars[:,1])), float(np.std(aFitPars[:,1]))])\n",
    "    \n",
    "    if AIC_LS2<=AIC_LS3:\n",
    "        S2_tauf_MC_stdOnly=np.array([float(np.std(aFitPars[:,0])), float(np.std(aFitPars[:,1]))*pico])\n",
    "        \n",
    "        p2x_min = p2x-S2_tauf_MC_stdOnly\n",
    "        p2x_max = p2x+S2_tauf_MC_stdOnly\n",
    "      \n",
    "    else:\n",
    "        S2_tauf_MC_stdOnly=np.array([float(np.std(aFitPars[:,0])), float(np.std(aFitPars[:,1]))*pico, float(np.std(aFitPars[:,2]))*pico])\n",
    "\n",
    "        p3x_min = p3x-S2_tauf_MC_stdOnly\n",
    "        p3x_max = p3x+S2_tauf_MC_stdOnly\n",
    "    \n",
    "    ####### END MONTE CARLO SIMULATION ##########\n",
    "\n",
    "    values=[rate1_field1,rate2_field1,rate3_field1,rate1_field2,rate2_field2,rate3_field2,\n",
    "            p2x[0],p2x[1],rate1LS2_field1,rate2LS2_field1,rate3LS2_field1,rate1LS2_field2,rate2LS2_field2,rate3LS2_field2,\n",
    "            Jw1LS2_field1,Jw2LS2_field1,Jw3LS2_field1,Jw1LS2_field2,Jw2LS2_field2,Jw3LS2_field2,\n",
    "            p3x[0],p3x[2],p3x[1],rate1LS3_field1,rate2LS3_field1,rate3LS3_field1,rate1LS3_field2,rate2LS3_field2,rate3LS3_field2,\n",
    "            Jw1LS3_field1,Jw2LS3_field1,Jw3LS3_field1,Jw1LS3_field2,Jw2LS3_field2,Jw3LS3_field2,AIC_LS2,AIC_LS3] # all results in one array\n",
    "    \n",
    "    \n",
    "    output=pd.DataFrame(values,indices) # dataframe describing the output which will be written to the file\n",
    "    output.to_csv(outputpath+\"/params_\"+meth3ID,sep=\" \", header=False) # write values to file\n",
    "\n",
    "    j += 1    \n",
    "    \n",
    "    # PLOTTING\n",
    "    \n",
    "    # Make a dictionary for latex formatting in the plot titles:\n",
    "    latex_title = {\"CBHB\": r\"-$C^{\\beta}H^{\\beta}$\",\n",
    "                   \"CDHD\": r\"-$C^{\\delta}H^{\\delta}$\",\n",
    "                   \"CEHE\": r\"-$C^{\\epsilon}H^{\\epsilon}$\",\n",
    "                   \"CD1HD1\": r\"-$C^{\\delta1}H^{\\delta1}$\",\n",
    "                   \"CD2HD2\": r\"-$C^{\\delta2}H^{\\delta2}$\",\n",
    "                   \"CG1HG1\": r\"-$C^{\\gamma1}H^{\\gamma1}$\",\n",
    "                   \"CG2HG2\": r\"-$C^{\\gamma2}H^{\\gamma2}$\"}\n",
    "\n",
    "    \n",
    "    if plotting:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        edge=0.2\n",
    "        ax = plt.subplot(111)\n",
    "        plt.subplots_adjust(bottom=edge, left=edge)\n",
    "        ax.tick_params(pad=10)\n",
    "        plt.title(variant[:3]+\" \"+variant[4:]+\" \"+meth3ID.split(\"-\")[0]+latex_title[meth3ID.split(\"-\")[1]], fontsize=20)\n",
    "\n",
    "        plt.plot(frequency, LS2(p2x, frequency)/pico, c=\"b\", linestyle=\"--\", label=r'NMR LS2 fit ($S^\\mathrm{2}_\\mathrm{axis}$='+str(\"%.2f\" % round(p2x[0],2))+r', $\\tau_\\mathrm{R}$='+str(\"%.1f\" % round(taum/1000/pico,1))+r' ns, $\\tau_\\mathrm{f}$='+str(\"%.1f\" % round(p2x[1]/pico,1))+r' ps)')\n",
    "        \n",
    "        if AIC_LS2<=AIC_LS3:\n",
    "            plt.fill_between(frequency,LS2(p2x_min,frequency)/pico,LS2(p2x_max,frequency)/pico,facecolor='lightgrey', interpolate=True, edgecolors=\"None\",label=\"Confidence interval (LS2)\")        \n",
    "        else:\n",
    "            plt.fill_between(frequency,LS3(p3x_min,frequency)/pico,LS3(p3x_max,frequency)/pico,facecolor='lightgrey', interpolate=True, edgecolors=\"None\",label=\"Confidence interval (LS3)\")        \n",
    "   \n",
    "        plt.plot(frequency, LS3(p3x, frequency)/pico, c=\"r\", linestyle=\"--\", label=r'NMR LS3 fit ($S^\\mathrm{2}_\\mathrm{axis}$='+str(\"%.2f\" % round(p3x[0],2))+r', $\\tau_\\mathrm{c}^\\mathrm{eff}$='+str(\"%.1f\" % round(p3.x[2]/1000,1))+r' ns, $\\tau_\\mathrm{f}$='+str(\"%.1f\" % round(p3.x[1],1))+r' ps)') # Plot of the data and the fit\n",
    "        \n",
    "        plt.errorbar(measuredfreq, JomegaD/pico, yerr=err_Jws, c=\"k\", linestyle=\"None\", fmt='o', capsize = 4, label=\"NMR Jw's at measured frequencies\", ms=3)\n",
    "        plt.xlabel(r'$\\omega [s^{-1}]$')\n",
    "        plt.ylabel(r'$J[ps]$')\n",
    "        ax.xaxis.set_major_formatter(mtick.ScalarFormatter(useMathText=True))\n",
    "        ax.yaxis.set_major_formatter(mtick.ScalarFormatter(useMathText=True))\n",
    "        plt.xlim(-10**8,2*10**9)\n",
    "        plt.legend(numpoints=1, fontsize=8)\n",
    "        plt.savefig(outputpath+\"/spec_dens_\"+meth3ID+\".pdf\",dpi=600)\n",
    "        plt.close()\n",
    "\n",
    " # Plot spectral density:\n",
    "    if subplots:\n",
    "\n",
    "        ax = plt.subplot(round(relax_times_exp.shape[0]/2), 2, j)\n",
    "        plt.subplots_adjust(top=0.99, right=0.99)\n",
    "        ax.tick_params(pad=10)\n",
    "        \n",
    "        ax.plot(frequency, LS2(p2x, frequency)/pico, c=\"b\", linestyle=\"--\", label=r'NMR LS2 fit ($S^\\mathrm{2}_\\mathrm{axis}$='+str(\"%.2f\" % round(p2x[0],2))+r', $\\tau_\\mathrm{R}$='+str(\"%.1f\" % round(taum/1000/pico,1))+r' ns, $\\tau_\\mathrm{f}$='+str(\"%.1f\" % round(p2x[1]/pico,1))+r' ps)')\n",
    "        \n",
    "        if AIC_LS2<=AIC_LS3:\n",
    "            ax.fill_between(frequency,LS2(p2x_min,frequency)/pico,LS2(p2x_max,frequency)/pico,facecolor='lightgrey', interpolate=True, edgecolors=\"None\",label=\"Confidence interval (LS2)\")        \n",
    "        else:\n",
    "            ax.fill_between(frequency,LS3(p3x_min,frequency)/pico,LS3(p3x_max,frequency)/pico,facecolor='lightgrey', interpolate=True, edgecolors=\"None\",label=\"Confidence interval (LS3)\")        \n",
    " \n",
    "        ax.plot(frequency, LS3(p3x, frequency)/pico, c=\"r\", linestyle=\"--\", label=r'NMR LS3 fit ($S^\\mathrm{2}_\\mathrm{axis}$='+str(\"%.2f\" % round(p3x[0],2))+r', $\\tau_\\mathrm{c}^\\mathrm{eff}$='+str(\"%.1f\" % round(p3.x[2]/1000,1))+r' ns, $\\tau_\\mathrm{f}$='+str(\"%.1f\" % round(p3.x[1],1))+r' ps)') # Plot of the data and the fit\n",
    "        \n",
    "        ax.errorbar(measuredfreq, JomegaD/pico, yerr=err_Jws, c=\"k\", linestyle=\"None\", fmt='o', capsize = 4, label=\"NMR Jw's at measured frequencies\", ms=3)\n",
    "\n",
    "        ax.set_xlabel(r'$\\omega [s^{-1}]$')\n",
    "        ax.set_ylabel(r'$J[ps]$')\n",
    "        plt.title(variant[:3]+\" \"+variant[4:]+\" \"+meth3ID.split(\"-\")[0]+latex_title[meth3ID.split(\"-\")[1]], fontsize=20)\n",
    "\n",
    "        ax.xaxis.set_major_formatter(mtick.ScalarFormatter(useMathText=True))\n",
    "        ax.yaxis.set_major_formatter(mtick.ScalarFormatter(useMathText=True))\n",
    "        plt.xlim(-10**8,2*10**9)\n",
    "        plt.legend(numpoints=1, fontsize=8, loc = 1)\n",
    "   \n",
    "    order_new = pd.DataFrame(columns = [\"methylID_full\", \"S2_LS2\", \"AIC_LS2\", \"S2_LS3\", \"AIC_LS3\", \"LS\", \"AIC\", \"S2\", \"S2_er\", \"tauf\", \"tauf_er\"])\n",
    "  \n",
    "    if AIC_LS2<=AIC_LS3:\n",
    "        order_new = order_new.append(pd.DataFrame({\"methylID_full\": meth3ID, \"S2_LS2\":[float(p2x[0])],\"AIC_LS2\": AIC_LS2, \n",
    "                                                       \"S2_LS3\":[float(p3x[0])],\"AIC_LS3\": AIC_LS3,\"LS\":\"LS2\",\"AIC\":AIC_LS2, \"S2\":[float(p2x[0])],\"S2_er\":[float(S2_tauf_MC_std[1])], \n",
    "                                                       \"tauf\":p2.x[1],\"tauf_er\": S2_tauf_MC_std[3]}, index = [0]), ignore_index = True, sort=False)\n",
    "        \n",
    "        print (j,\"\\t\",meth3ID,\"\\t\",\"S2\", \"%.2f\" % p2x[0],\"±\", \"%.3f\" % S2_tauf_MC_std[1],\"tau_f\", \"%1.2f\" % p2.x[1],\"±\", \"%.2f\" % S2_tauf_MC_std[3] ,\"LS2 AIC\", \"%.2f\" % AIC_LS2)\n",
    "        print (j,\"\\t\",meth3ID,\"\\t\",\"S2\", \"%.2f\" % p2x[0],\"±\", \"%.3f\" % S2_tauf_MC_std[1],\"tau_f\", \"%1.2f\" % p2.x[1],\"±\", \"%.2f\" % S2_tauf_MC_std[3] ,\"LS2 AIC\", \"%.2f\" % AIC_LS2, file=f)\n",
    "\n",
    "    else:\n",
    "        order_new = order_new.append(pd.DataFrame({\"methylID_full\": meth3ID, \"S2_LS2\":[float(p2x[0])],\"AIC_LS2\": AIC_LS2, \n",
    "                                                       \"S2_LS3\":[float(p3x[0])],\"AIC_LS3\": AIC_LS3,\"LS\":\"LS3\",\"AIC\":AIC_LS3, \"S2\":[float(p3x[0])],\"S2_er\":[float(S2_tauf_MC_std[1])], \n",
    "                                                       \"tauf\":p3.x[1],\"tauf_er\": S2_tauf_MC_std[3]}, index = [0]), ignore_index = True, sort=False)\n",
    "        \n",
    "        print (j,\"\\t\",meth3ID,\"\\t\",\"S2\", \"%.2f\" % p3x[0],\"±\", \"%.3f\" % S2_tauf_MC_std[1],\"tau_f\", \"%1.2f\" % p3.x[1],\"±\", \"%.2f\" % S2_tauf_MC_std[3] ,\"LS3 AIC\", \"%.2f\" % AIC_LS3)\n",
    "        print (j,\"\\t\",meth3ID,\"\\t\",\"S2\", \"%.2f\" % p3x[0],\"±\", \"%.3f\" % S2_tauf_MC_std[1],\"tau_f\", \"%1.2f\" % p3.x[1],\"±\", \"%.2f\" % S2_tauf_MC_std[3] ,\"LS3 AIC\", \"%.2f\" % AIC_LS3, file=f)\n",
    "\n",
    "        \n",
    "    order = order.append(order_new) # append order parameter to dataframe containing all order parameter\n",
    "\n",
    "order.to_csv(outputpath+\"/order_\"+variant+\"_methyl.dat\",header=True,sep=\"\\t\", float_format='%5.3f') # write order parameter to file\n",
    "print (\"Printing the plots...\")\n",
    "\n",
    "if subplots:      \n",
    "    fig1.tight_layout(rect=[0, 0.03, 1, 0.96])\n",
    "    fig1.savefig(str(outputpath+\"/\"+variant+\"_spec_dens.pdf\"), dpi = 1200, bbox_inches='tight') \n",
    "    \n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
