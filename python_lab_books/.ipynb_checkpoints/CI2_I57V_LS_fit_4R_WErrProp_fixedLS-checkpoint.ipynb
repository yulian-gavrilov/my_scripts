{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input to fit.py is ACFs for all methyles. Each line is a time frame and each column is a methyl group.\n",
    "# Time frames are exp weighted (so, not all frames are there)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import pi, r_\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "import pandas as pd\n",
    "from matplotlib import rc\n",
    "import matplotlib.ticker as mtick\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "#import decimal\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'size'   : 16}\n",
    "rc('font', **font)\n",
    "\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams[\"lines.linewidth\"]=2\n",
    "\n",
    "#inputfile=sys.argv[1] # ACFs\n",
    "#mutant=sys.argv[2] # name of the molelule\n",
    "#plotting=bool(int(sys.argv[3])) # plots should be created ?\n",
    "\n",
    "plotting=True # plots should be created ?\n",
    "subplots=True\n",
    "pico=1.*10**(-12) # picoseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file with QUADRIC analysis of the protein backbone --> has to be done before methyl analysis!!!\n",
    "\n",
    "inputpath = \".\"\n",
    "\n",
    "### CHANGE ACCORDINGLY !!! :\n",
    "mutant='CI2_WT' # name of the molelule\n",
    "tumbling = \"iso\" # iso/ani\n",
    "outputpath = inputpath+\"/\"+mutant+\"/\"+tumbling\n",
    "## CREATE OUTPUT FOLDER !!! \n",
    "\n",
    "tumbling_file=inputpath+\"/analysis_\"+tumbling+\"_\"+mutant\n",
    "inputfile_rates=inputpath+\"/\"+mutant+\"_sch_times.csv\"\n",
    "\n",
    "#output.to_csv(outputpath+\"/params_\"+meth3ID,sep=\" \", header=False) # write values to file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Larmor frquency of deuterium\n",
    "omega_D_600=2.*pi*92.1298227037992*1000000 # @600 MHz\n",
    "omega_D_750=2.*pi*115.138869111022*1000000 # @750 MHz\n",
    "# frequencies of spectral density used for the fit / usually frequencies measured in NMR\n",
    "\n",
    "# !!! create array with five frequences  \n",
    "measuredfreq_600=np.array([i*omega_D_600 for i in [0,1,2]])\n",
    "measuredfreq_750=np.array([i*omega_D_750 for i in [0,1,2]])\n",
    "\n",
    "#measuredfreq = np.concatenate((measuredfreq_600, measuredfreq_750))\n",
    "measuredfreq = np.array([measuredfreq_600[0], measuredfreq_750[0],measuredfreq_600[1], measuredfreq_750[1],\n",
    "               measuredfreq_600[2], measuredfreq_750[2]])\n",
    "\n",
    "frequency = np.linspace(0, 2*10**9, 100)\n",
    "# prefector\n",
    "pre=2*np.pi*167000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to calculate methyl relaxation rates from spectral density points\n",
    "def R1(x,y,z):\n",
    "    return 3./16.*pre**2*(0*x+ 1*y+4*z)\n",
    "def R3(x,y,z):                            # R2 <-> R3  !!!\n",
    "    return 3./16.*pre**2*(0*x+ 3*y+0*z)\n",
    "def R2(x,y,z):\n",
    "    return 1./32.*pre**2*(9*x+15*y+6*z)\n",
    "def R4(x,y,z):\n",
    "    return 3./16.*pre**2*(0*x+ 1*y+2*z)\n",
    "\n",
    "# functios to calculate spectral density points from methyl relaxation rates\n",
    "\n",
    "A = 3./16.*pre**2\n",
    "B = 1./32.*pre**2\n",
    "#print (A, B)\n",
    "def J_omega_D(R1,R2,R3):\n",
    "    return R3/(3*A) - R1*0 - R2*0\n",
    "\n",
    "def J_2omega_D(R1,R2,R3):\n",
    "    return (R1/A - R3/(3*A))/4 - R2*0\n",
    "def J_2omega_D_b(R2,R3,R4):\n",
    "    return (R4/A - R3/(3*A))/2 - R2*0  # return (R4/A - R3/(3*A))/2 - R2*0\n",
    "\n",
    "def J_0(R1,R2,R3):\n",
    "    return ( R2/B - 5*R3/A - 1.5*R1/A + 0.5*R3/A ) /9\n",
    "def J_0_b(R2,R3,R4):\n",
    "    return ( R2/B - 5*R3/A - 3*R4/A + R3/A ) /9\n",
    "\n",
    "\n",
    "# calculate Aikaike information criterion\n",
    "def CHIsq(Rmodel,Rnmr,Rerror):\n",
    "    return sum([((Rmodel[i]-Rnmr[i])/Rerror[i])**2 for i in [0,1,2]])\n",
    "# indices of strings for output file\n",
    "indices=[\"R1spec_600\",\"R2spec_600\",\"R3spec_600\",\"R1spec_750\",\"R2spec_750\",\"R3spec_750\", \n",
    "         \"SLS2\",\"taufLS2\",\"R1LS2_600\",\"R2LS2_600\",\"R3LS2_600\",\"R1LS2_750\",\"R2LS2_750\",\"R3LS2_750\",\n",
    "         \"Jw1LS2_600\",\"Jw2LS2_600\",\"Jw3LS2_600\",\"Jw1LS2_750\",\"Jw2LS2_750\",\"Jw3LS2_750\",\n",
    "         \"SLS3\",\"taurLS3\",\"taufLS3\",\"R1LS3_600\",\"R2LS3_600\",\"R3LS3_600\",\"R1LS3_750\",\"R2LS3_750\",\"R3LS3_750\",\n",
    "         \"Jw1LS3_600\",\"Jw2LS3_600\",\"Jw3LS3_600\",\"Jw1LS3_750\",\"Jw2LS3_750\",\"Jw3LS3_750\",\"AIC_LS2\",\"AIC_LS3\"]\n",
    "# create empty dataframe of order parameter\n",
    "order=pd.DataFrame()\n",
    "\n",
    "data1 = pd.read_csv(inputfile_rates, sep=\",\", index_col=[0])\n",
    "test1= np.size(data1,0)\n",
    "\n",
    "def STDV(J1,J2_600,J3_600,J2_750,J3_750,J1LS,J2_600LS,J3_600LS,J2_750LS,J3_750LS):\n",
    "    return math.sqrt(((J1-J1LS)**2+(J2_600-J2_600LS)**2+(J3_600-J3_600LS)**2+(J2_750-J2_750LS)**2+(J3_750-J3_750LS)**2)/5)\n",
    "\n",
    "def Chi2_Jpre (Jomegas_pre): # x = J_0, y = J_D, z = J_2D\n",
    "    return  (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+4*Jomegas_pre[3]))-R1_exp_600)/R1_err_exp_600)**2 + \\\n",
    "            (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[1]+6*Jomegas_pre[3]))-R2_exp_600)/R2_err_exp_600)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[1]+0*Jomegas_pre[3]))-R3_exp_600)/R3_err_exp_600)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+2*Jomegas_pre[3]))-R4_exp_600)/R4_err_exp_600)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+4*Jomegas_pre[4]))-R1_exp_750)/R1_err_exp_750)**2 + \\\n",
    "            (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[2]+6*Jomegas_pre[4]))-R2_exp_750)/R2_err_exp_750)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[2]+0*Jomegas_pre[4]))-R3_exp_750)/R3_err_exp_750)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+2*Jomegas_pre[4]))-R4_exp_750)/R4_err_exp_750)**2 \n",
    "\n",
    "def LS2ns_MC(x,p11,p22):\n",
    "    return 2./5.*(1./9.*p11*taumps/(1.+(x*taumps)**2)+(1.-1./9.*p11)*taumps*p22/(taumps+p22+(x*taumps*p22)**2/(taumps+p22))) # Lipari-Szabo function\n",
    "   \n",
    "def LS3ns_MC(x,p11,p22,p33):    \n",
    "    return 2./5.*(1./9.*p11*p33/(1.+(x*p33)**2)+(1.-1./9.*p11)*p33*p22/(p33+p22+(x*p33*p22)**2/(p33+p22))) # Lipari-Szabo function\n",
    "\n",
    "def ERRCHI2(All,A,B,C,D,E,F,G,H):\n",
    "    return math.sqrt(((A-All)**2+(B-All)**2+(C-All)**2+(D-All)**2+(E-All)**2+(F-All)**2+(G-All)**2+(H-All)**2)/7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2A = (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+4*Jomegas_pre[3]))-R1_exp_600)/R1_err_exp_600)**2\n",
    "# chi2B = (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[1]+6*Jomegas_pre[3]))-R2_exp_600)/R2_err_exp_600)**2\n",
    "# chi2C = (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[1]+0*Jomegas_pre[3]))-R3_exp_600)/R3_err_exp_600)**2\n",
    "# chi2D = (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+2*Jomegas_pre[3]))-R4_exp_600)/R4_err_exp_600)**2\n",
    "# chi2E = (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+4*Jomegas_pre[4]))-R1_exp_750)/R1_err_exp_750)**2\n",
    "# chi2F = (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[2]+6*Jomegas_pre[4]))-R2_exp_750)/R2_err_exp_750)**2\n",
    "# chi2G = (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[2]+0*Jomegas_pre[4]))-R3_exp_750)/R3_err_exp_750)**2\n",
    "# chi2H = (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+2*Jomegas_pre[4]))-R4_exp_750)/R4_err_exp_750)**2\n",
    "    \n",
    "# chiAll = np.array([chi2A,chi2B,chi2C,chi2D,chi2E,chi2E,chi2F,chi2G,chi2H])\n",
    "\n",
    "\n",
    "def Chi2_JpreA (Jomegas_pre): # x = J_0, y = J_D, z = J_2D\n",
    "    return  (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[1]+6*Jomegas_pre[3]))-R2_exp_600)/R2_err_exp_600)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[1]+0*Jomegas_pre[3]))-R3_exp_600)/R3_err_exp_600)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+2*Jomegas_pre[3]))-R4_exp_600)/R4_err_exp_600)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+4*Jomegas_pre[4]))-R1_exp_750)/R1_err_exp_750)**2 + \\\n",
    "            (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[2]+6*Jomegas_pre[4]))-R2_exp_750)/R2_err_exp_750)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[2]+0*Jomegas_pre[4]))-R3_exp_750)/R3_err_exp_750)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+2*Jomegas_pre[4]))-R4_exp_750)/R4_err_exp_750)**2\n",
    "\n",
    "def Chi2_JpreB (Jomegas_pre): # x = J_0, y = J_D, z = J_2D\n",
    "    return  (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+4*Jomegas_pre[3]))-R1_exp_600)/R1_err_exp_600)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[1]+0*Jomegas_pre[3]))-R3_exp_600)/R3_err_exp_600)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+2*Jomegas_pre[3]))-R4_exp_600)/R4_err_exp_600)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+4*Jomegas_pre[4]))-R1_exp_750)/R1_err_exp_750)**2 + \\\n",
    "            (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[2]+6*Jomegas_pre[4]))-R2_exp_750)/R2_err_exp_750)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[2]+0*Jomegas_pre[4]))-R3_exp_750)/R3_err_exp_750)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+2*Jomegas_pre[4]))-R4_exp_750)/R4_err_exp_750)**2\n",
    "\n",
    "\n",
    "def Chi2_JpreC (Jomegas_pre): # x = J_0, y = J_D, z = J_2D\n",
    "    return  (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+4*Jomegas_pre[3]))-R1_exp_600)/R1_err_exp_600)**2 + \\\n",
    "            (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[1]+6*Jomegas_pre[3]))-R2_exp_600)/R2_err_exp_600)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+2*Jomegas_pre[3]))-R4_exp_600)/R4_err_exp_600)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+4*Jomegas_pre[4]))-R1_exp_750)/R1_err_exp_750)**2 + \\\n",
    "            (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[2]+6*Jomegas_pre[4]))-R2_exp_750)/R2_err_exp_750)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[2]+0*Jomegas_pre[4]))-R3_exp_750)/R3_err_exp_750)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+2*Jomegas_pre[4]))-R4_exp_750)/R4_err_exp_750)**2\n",
    "\n",
    "def Chi2_JpreD (Jomegas_pre): # x = J_0, y = J_D, z = J_2D\n",
    "    return  (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+4*Jomegas_pre[3]))-R1_exp_600)/R1_err_exp_600)**2 + \\\n",
    "            (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[1]+6*Jomegas_pre[3]))-R2_exp_600)/R2_err_exp_600)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[1]+0*Jomegas_pre[3]))-R3_exp_600)/R3_err_exp_600)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+4*Jomegas_pre[4]))-R1_exp_750)/R1_err_exp_750)**2 + \\\n",
    "            (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[2]+6*Jomegas_pre[4]))-R2_exp_750)/R2_err_exp_750)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[2]+0*Jomegas_pre[4]))-R3_exp_750)/R3_err_exp_750)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+2*Jomegas_pre[4]))-R4_exp_750)/R4_err_exp_750)**2\n",
    "\n",
    "def Chi2_JpreE (Jomegas_pre): # x = J_0, y = J_D, z = J_2D\n",
    "    return  (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+4*Jomegas_pre[3]))-R1_exp_600)/R1_err_exp_600)**2 + \\\n",
    "            (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[1]+6*Jomegas_pre[3]))-R2_exp_600)/R2_err_exp_600)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[1]+0*Jomegas_pre[3]))-R3_exp_600)/R3_err_exp_600)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+2*Jomegas_pre[3]))-R4_exp_600)/R4_err_exp_600)**2 + \\\n",
    "            (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[2]+6*Jomegas_pre[4]))-R2_exp_750)/R2_err_exp_750)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[2]+0*Jomegas_pre[4]))-R3_exp_750)/R3_err_exp_750)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+2*Jomegas_pre[4]))-R4_exp_750)/R4_err_exp_750)**2\n",
    "\n",
    "def Chi2_JpreF (Jomegas_pre): # x = J_0, y = J_D, z = J_2D\n",
    "    return  (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+4*Jomegas_pre[3]))-R1_exp_600)/R1_err_exp_600)**2 + \\\n",
    "            (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[1]+6*Jomegas_pre[3]))-R2_exp_600)/R2_err_exp_600)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[1]+0*Jomegas_pre[3]))-R3_exp_600)/R3_err_exp_600)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+2*Jomegas_pre[3]))-R4_exp_600)/R4_err_exp_600)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+4*Jomegas_pre[4]))-R1_exp_750)/R1_err_exp_750)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[2]+0*Jomegas_pre[4]))-R3_exp_750)/R3_err_exp_750)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+2*Jomegas_pre[4]))-R4_exp_750)/R4_err_exp_750)**2\n",
    "\n",
    "def Chi2_JpreG (Jomegas_pre): # x = J_0, y = J_D, z = J_2D\n",
    "    return  (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+4*Jomegas_pre[3]))-R1_exp_600)/R1_err_exp_600)**2 + \\\n",
    "            (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[1]+6*Jomegas_pre[3]))-R2_exp_600)/R2_err_exp_600)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[1]+0*Jomegas_pre[3]))-R3_exp_600)/R3_err_exp_600)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+2*Jomegas_pre[3]))-R4_exp_600)/R4_err_exp_600)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+4*Jomegas_pre[4]))-R1_exp_750)/R1_err_exp_750)**2 + \\\n",
    "            (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[2]+6*Jomegas_pre[4]))-R2_exp_750)/R2_err_exp_750)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+2*Jomegas_pre[4]))-R4_exp_750)/R4_err_exp_750)**2\n",
    "\n",
    "def Chi2_JpreH (Jomegas_pre): # x = J_0, y = J_D, z = J_2D\n",
    "    return  (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+4*Jomegas_pre[3]))-R1_exp_600)/R1_err_exp_600)**2 + \\\n",
    "            (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[1]+6*Jomegas_pre[3]))-R2_exp_600)/R2_err_exp_600)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[1]+0*Jomegas_pre[3]))-R3_exp_600)/R3_err_exp_600)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+2*Jomegas_pre[3]))-R4_exp_600)/R4_err_exp_600)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+4*Jomegas_pre[4]))-R1_exp_750)/R1_err_exp_750)**2 + \\\n",
    "            (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[2]+6*Jomegas_pre[4]))-R2_exp_750)/R2_err_exp_750)**2 + \\\n",
    "            (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[2]+0*Jomegas_pre[4]))-R3_exp_750)/R3_err_exp_750)**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methID_dict = {\"Ala\":\"ALA\", \"Ile\":\"ILE\", \"Leu\":\"LEU\", \"Met\":\"MET\", \"Thr\":\"THR\", \"Val\":\"VAL\",\n",
    "               \"Cb\":\"-CB\", \"Hb\":\"HB\", \"Cg1\":\"-CG1\",\"Cg2\":\"-CG2\", \"Hg1\":\"HG1\",\"Hg2\":\"HG2\",\"Cd1\":\"-CD1\", \"Hd1\":\"HD1\",\n",
    "               \"Cd2\":\"-CD2\", \"Hd2\":\"HD2\", \"Ce\":\"-CE\", \"He\":\"HE\"}\n",
    "    \n",
    "# Run a loop for all methyl groups:\n",
    "\n",
    "fig1, axes1 = plt.subplots(nrows = round(data1.shape[0]/2), ncols = 2, figsize = (11, 105))\n",
    "#j = 0\n",
    "#print (axes1)\n",
    "#print (axes1.flatten())\n",
    "#a = enumerate(axes1.flatten())\n",
    "#print (a)             \n",
    "\n",
    "LSmodel = np.array([3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 2, 2, 3, 3, 3, 2, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 3, 3, 3, 3, 2, 2, 2, 3, 3, 2])  # LS for WT, L49I, I57V\n",
    "\n",
    "j=0\n",
    "for i, ax in enumerate(axes1.flatten()):\n",
    "#for j in range(np.size(data1,0)): \n",
    "#for j in range(8,9):\n",
    "    if j == np.size(data1,0): # j starts from 0 , not from 1 !\n",
    "        break    \n",
    "#for j in range(np.size(data1,0)): # for all methyl groups:\n",
    "    Times=data1.iloc[j][::2] # in ms\n",
    "    Err = data1.iloc[j][1::2] # in ms\n",
    "\n",
    "    \n",
    "    #methyl=np.array(data[methID])[1:] # numpy array with values from specific methyl group\n",
    "    \n",
    "    Rates = 1/(Times*0.001) # R1_600 R2_600 R3_600 R4_600 R1_750 R2_750 R3_750 R4_750\n",
    "    Rates_err = np.divide(Err/0.001, Times**2) # R1_err_600 R2_err_600 R3_err_600 R4_err_600 R1_err_750 R2_err_750 R3_err_750 R4err_err_750\n",
    "\n",
    "    Rates1to3 = np.array([Rates[0],Rates[1],Rates[2],Rates[4],Rates[5],Rates[6]])\n",
    "    Rates_err1to3 = np.array([Rates_err[0],Rates_err[1],Rates_err[2],Rates_err[4],Rates_err[5],Rates_err[6]])\n",
    "    \n",
    "    print (Times)\n",
    "    \n",
    "    Jzero_600=J_0(Rates[0],Rates[1],Rates[2]) \n",
    "    Jzero_750=J_0(Rates[4],Rates[5],Rates[6]) # J_0(R1,R2,R3)\n",
    "\n",
    "    Jzero_600b=J_0_b(Rates[1],Rates[2],Rates[3]) \n",
    "    Jzero_750b=J_0_b(Rates[5],Rates[6],Rates[7]) # J_0_b(R2,R3,R4)\n",
    "\n",
    "    Jw_D_600=J_omega_D(Rates[0],Rates[1],Rates[2]) \n",
    "    Jw_D_750=J_omega_D(Rates[4],Rates[5],Rates[6]) # J_omega_D(R1,R2,R3)\n",
    "    \n",
    "    J2w_D_600=J_2omega_D(Rates[0],Rates[1],Rates[2]) \n",
    "    J2w_D_750=J_2omega_D(Rates[4],Rates[5],Rates[6]) # J_2omega_D(R1,R2,R3)\n",
    "\n",
    "    J2w_D_600b=J_2omega_D_b(Rates[1],Rates[2],Rates[3]) \n",
    "    J2w_D_750b=J_2omega_D_b(Rates[5],Rates[6],Rates[7]) # J_2omega_D_b(R2,R3,R4)\n",
    "\n",
    "    \n",
    "    ##############\n",
    "    \n",
    "    R1_exp_600 = Rates[0]; R2_exp_600 = Rates[1]; R3_exp_600 = Rates[2]; R4_exp_600 = Rates[3];\n",
    "    R1_exp_750 = Rates[4]; R2_exp_750 = Rates[5]; R3_exp_750 = Rates[6]; R4_exp_750 = Rates[7];\n",
    "    \n",
    "    R1_err_exp_600 = Rates_err[0]; R2_err_exp_600 = Rates_err[1]; R3_err_exp_600 = Rates_err[2]; R4_err_exp_600 = Rates_err[3];\n",
    "    R1_err_exp_750 = Rates_err[0]; R2_err_exp_750 = Rates_err[1]; R3_err_exp_750 = Rates_err[2]; R4_err_exp_750 = Rates_err[3];\n",
    "      \n",
    "    \n",
    "    ## MINIMIZATION USING CHI^2 FUNCTION Chi2_Jpre\n",
    "    ## DOES NOT WORK WITH LOW NUMBERS (10^-12). CONVERTED TO PICOSECONDS\n",
    "\n",
    "    measuredfreq = np.array([measuredfreq_600[0],measuredfreq_600[1], measuredfreq_750[1], measuredfreq_600[2], measuredfreq_750[2]])\n",
    "    \n",
    "    Jomegas_pre = np.array([Jzero_600, Jw_D_600, Jw_D_750, J2w_D_600, J2w_D_750])*pre**2  # initial guess of Jomegas (x, y, z)\n",
    "    #result1 = minimize(Chi2_J, Jomegas, method='nelder-mead', options={'disp': False})\n",
    "    #print(\"Initial\", Chi2_Jpre(Jomegas_pre))\n",
    "    positive = { 'type': 'ineq', 'fun' : lambda x: np.array(x) }\n",
    "    #positive = { 'type': 'ineq', 'fun' : lambda x: x[0] }\n",
    "    opt = { 'maxiter': 500 , 'disp': False}\n",
    "   \n",
    "    result1 = optimize.minimize( Chi2_Jpre, Jomegas_pre, jac = False, constraints = positive, method = 'SLSQP', options = opt )     \n",
    "    JomegaD = np.array([result1.x[0], result1.x[1], result1.x[2], result1.x[3], result1.x[4]])/pre**2\n",
    "    \n",
    "    resultA = optimize.minimize( Chi2_JpreA, Jomegas_pre, jac = False, constraints = positive, method = 'SLSQP', options = opt )     \n",
    "    JomegaD_A = np.array([resultA.x[0], resultA.x[1], resultA.x[2], resultA.x[3], resultA.x[4]])/pre**2\n",
    "        \n",
    "    resultB = optimize.minimize( Chi2_JpreB, Jomegas_pre, jac = False, constraints = positive, method = 'SLSQP', options = opt )     \n",
    "    JomegaD_B = np.array([resultB.x[0], resultB.x[1], resultB.x[2], resultB.x[3], resultB.x[4]])/pre**2\n",
    "        \n",
    "    resultC = optimize.minimize( Chi2_JpreC, Jomegas_pre, jac = False, constraints = positive, method = 'SLSQP', options = opt )     \n",
    "    JomegaD_C = np.array([resultC.x[0], resultC.x[1], resultC.x[2], resultC.x[3], resultC.x[4]])/pre**2\n",
    "    \n",
    "    resultD = optimize.minimize( Chi2_JpreD, Jomegas_pre, jac = False, constraints = positive, method = 'SLSQP', options = opt )     \n",
    "    JomegaD_D = np.array([resultD.x[0], resultD.x[1], resultD.x[2], resultD.x[3], resultD.x[4]])/pre**2\n",
    "        \n",
    "    resultE = optimize.minimize( Chi2_JpreE, Jomegas_pre, jac = False, constraints = positive, method = 'SLSQP', options = opt )     \n",
    "    JomegaD_E = np.array([resultE.x[0], resultE.x[1], resultE.x[2], resultE.x[3], resultE.x[4]])/pre**2\n",
    "        \n",
    "    resultF = optimize.minimize( Chi2_JpreF, Jomegas_pre, jac = False, constraints = positive, method = 'SLSQP', options = opt )     \n",
    "    JomegaD_F = np.array([resultF.x[0], resultF.x[1], resultF.x[2], resultF.x[3], resultF.x[4]])/pre**2\n",
    "        \n",
    "    resultG = optimize.minimize( Chi2_JpreG, Jomegas_pre, jac = False, constraints = positive, method = 'SLSQP', options = opt )     \n",
    "    JomegaD_G = np.array([resultG.x[0], resultG.x[1], resultG.x[2], resultG.x[3], resultG.x[4]])/pre**2\n",
    "        \n",
    "    resultH = optimize.minimize( Chi2_JpreH, Jomegas_pre, jac = False, constraints = positive, method = 'SLSQP', options = opt )     \n",
    "    JomegaD_H = np.array([resultH.x[0], resultH.x[1], resultH.x[2], resultH.x[3], resultH.x[4]])/pre**2\n",
    "\n",
    "    \n",
    "#     methIDtest = data1.index[j] \n",
    "#     #np.set_printoptions(suppress=True)\n",
    "#     print('res', methIDtest)\n",
    "#     print('Init', Jomegas_pre)\n",
    "#     print('All', JomegaD)\n",
    "#     print('A', JomegaD_A)\n",
    "#     print('B', JomegaD_B)\n",
    "#     print('C', JomegaD_C)\n",
    "#     print('D', JomegaD_D)\n",
    "#     print('E', JomegaD_E)\n",
    "#     print('F', JomegaD_F)\n",
    "#     print('G', JomegaD_G)\n",
    "#     print('H', JomegaD_H)\n",
    "\n",
    "\n",
    "    \n",
    "# define error for JomegaD by minimizing Chi2_Jpre with different N [ (R_Jw - Rexp/Rexp_err)^2 elements ]\n",
    "    \n",
    "#  (chi2A)           (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+4*Jomegas_pre[3]))-R1_exp_600)/R1_err_exp_600)**2 + \\\n",
    "#  (chi2B)           (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[1]+6*Jomegas_pre[3]))-R2_exp_600)/R2_err_exp_600)**2 + \\\n",
    "#  (chi2C)           (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[1]+0*Jomegas_pre[3]))-R3_exp_600)/R3_err_exp_600)**2 + \\\n",
    "#  (chi2D)           (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[1]+2*Jomegas_pre[3]))-R4_exp_600)/R4_err_exp_600)**2 + \\\n",
    "\n",
    "#  (chi2E)           (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+4*Jomegas_pre[4]))-R1_exp_750)/R1_err_exp_750)**2 + \\\n",
    "#  (chi2F)           (((1./32.*(9*Jomegas_pre[0]+15*Jomegas_pre[2]+6*Jomegas_pre[4]))-R2_exp_750)/R2_err_exp_750)**2 + \\\n",
    "#  (chi2G)           (((3./16.*(0*Jomegas_pre[0]+ 3*Jomegas_pre[2]+0*Jomegas_pre[4]))-R3_exp_750)/R3_err_exp_750)**2 + \\\n",
    "#  (chi2H)           (((3./16.*(0*Jomegas_pre[0]+ 1*Jomegas_pre[2]+2*Jomegas_pre[4]))-R4_exp_750)/R4_err_exp_750)**2\n",
    "    \n",
    "# for Jw0      e.g. Jomegas_pre[0] B,F elements contain this Jw => at least one of them should be used in the minimization\n",
    "\n",
    "# for JwD_600  e.g. Jomegas_pre[1] A,B,C,D\n",
    "# for Jw2D_600 e.g. Jomegas_pre[3] A,B,C,D\n",
    "\n",
    "# for JwD_750  e.g. Jomegas_pre[2] E,F,G,H\n",
    "# for Jw2D_750 e.g. Jomegas_pre[4] E,F,G,H\n",
    "\n",
    "# Since all Jw's are in at least one chi2 element, normal jackknife algortm can be used.\n",
    "\n",
    "\n",
    "\n",
    "    ##############\n",
    "     \n",
    "    methID = data1.index[j] \n",
    "    \n",
    "    match = re.search('(\\d+)(\\w{3})(\\w+)_\\d+\\w{3}(\\w+)', methID)\n",
    "    resN = match.group(1) if match else None\n",
    "    resName = match.group(2) if match else None\n",
    "    carbon = match.group(3) if match else None\n",
    "    hydrogen = match.group(4) if match else None\n",
    "    #if (resN): print(resN)\n",
    "    #if (resName): print(resName)\n",
    "    #if (carbon): print(carbon)\n",
    "    #if (hydrogen): print(hydrogen)\n",
    "    \n",
    "    methIDnew= \" %s%s-%s%s\" % (resName, resN, carbon, hydrogen)\n",
    "    \n",
    "    meth3ID = str(methID_dict[match.group(2)] + match.group(1) + methID_dict[match.group(3)] + methID_dict[match.group(4)])\n",
    "    if resName==\"Ile\" and carbon==\"Cd1\":\n",
    "        meth3ID=meth3ID.replace(\"-CD1HD1\",\"-CDHD\")\n",
    "        \n",
    "                \n",
    "    with open(tumbling_file) as origin_file: # extract tumbling time from external tumbling\n",
    "        for line in origin_file:\n",
    "            #methylID = re.findall(meth3ID, line)\n",
    "            #if (methylID): print(line)\n",
    "\n",
    "            match = re.search('(\\d+\\.\\d+)\\s*\\t*\\[(\\w{3}\\d+\\-\\w+\\d*\\w+\\d*)\\]', line) # 4024.462292 [ILE30-CG2HG2]\n",
    "            methylID = match.group(2) if match else None\n",
    "            #if (methylID): print(methylID)\n",
    "            if methylID:\n",
    "                #line = line.split(' ')[3].split('\\t')[0]\n",
    "                #line = line.split(' ')[0]\n",
    "                line = match.group(1) if match else None\n",
    "# !! pico vs nano in input\n",
    "                taum=float(line)*1000*pico\n",
    "                #taum=float(line)*pico\n",
    "                #print(line, methylID, taum)\n",
    "                \n",
    "    ##LS2\n",
    "    \n",
    "    LS2 = lambda p,x: 2./5.*(1./9.*p[0]*taum/(1.+(x*taum)**2)+(1.-1./9.*p[0])*taum*p[1]/(taum+p[1]+(x*taum*p[1])**2/(taum+p[1]))) # Lipari-Szabo function\n",
    "    errLS2func = lambda p, x, y: LS2(p, x) - y # Distance to the target function\n",
    "    taumps=taum/pico\n",
    "    p02 = [0.5, 50] # Initial guess for the parameters\n",
    "    bounds2_min = [0.,0.]\n",
    "    bounds2_max = [1.,taumps]\n",
    "    bounds2 = [bounds2_min, bounds2_max]\n",
    "    LS2ns = lambda p,x: 2./5.*(1./9.*p[0]*taumps/(1.+(x*taumps)**2)+(1.-1./9.*p[0])*taumps*p[1]/(taumps+p[1]+(x*taumps*p[1])**2/(taumps+p[1]))) # Lipari-Szabo function in ns\n",
    "    errLS2nsfunc = lambda p, x, y: LS2ns(p, x) - y # Distance to the target function\n",
    "    p2 = optimize.least_squares(errLS2nsfunc, p02, bounds=bounds2, args=(measuredfreq*pico, JomegaD/pico)) # fit with LS2 function\n",
    "    p2x=np.array([float(p2.x[0]), float(p2.x[1]*pico)])\n",
    "    \n",
    "    #print (errLS2nsfunc(p,x,y))\n",
    "    #print (p2x)\n",
    "    #print (p2)\n",
    "    \n",
    "    \n",
    "#     # This can be used to estimate the Covariance Matrix of the parameters using the following formula: Sigma = (J'J)^-1.\n",
    "#     J = p2.jac\n",
    "#     cov = np.linalg.inv(J.T.dot(J))\n",
    "#     # To find the variance of the parameters one can then use:\n",
    "#     var = np.sqrt(np.diagonal(cov))\n",
    "#     #print (var)\n",
    "\n",
    "    ##LS3\n",
    "\n",
    "    LS3 = lambda p,x: 2./5.*(1./9.*p[0]*p[2]/(1.+(x*p[2])**2)+(1.-1./9.*p[0])*p[2]*p[1]/(p[2]+p[1]+(x*p[2]*p[1])**2/(p[2]+p[1]))) # Lipari-Szabo function\n",
    "    errLS3func = lambda p, x, y: LS2(p, x) - y # Distance to the target function\n",
    "    p03 = [0.5, 100, 5000] # Initial guess for the parameters\n",
    "    bounds3_min = [0.,0., 1000.]\n",
    "    bounds3_max = [1.,500,10000]\n",
    "    bounds3 = [bounds3_min, bounds3_max]\n",
    "    LS3ns = lambda p,x: 2./5.*(1./9.*p[0]*p[2]/(1.+(x*p[2])**2)+(1.-1./9.*p[0])*p[2]*p[1]/(p[2]+p[1]+(x*p[2]*p[1])**2/(p[2]+p[1]))) # Lipari-Szabo function\n",
    "    errLS3nsfunc = lambda p, x, y: LS3ns(p, x) - y # Distance to the target function\n",
    "    p3 = optimize.least_squares(errLS3nsfunc, p03, bounds=bounds3, args=(measuredfreq*pico, JomegaD/pico)) # fit with LS3 function\n",
    "    p3x=np.array([float(p3.x[0]), float(p3.x[1]*pico), float(p3.x[2]*pico)])\n",
    "\n",
    "    ##\n",
    "    rate1_600=R1(JomegaD[0],JomegaD[1],JomegaD[3]) # calculation of relaxation rates\n",
    "    rate2_600=R2(JomegaD[0],JomegaD[1],JomegaD[3]) \n",
    "    rate3_600=R3(JomegaD[0],JomegaD[1],JomegaD[3])\n",
    "   \n",
    "    rate1_750=R1(JomegaD[0],JomegaD[2],JomegaD[4])\n",
    "    rate2_750=R2(JomegaD[0],JomegaD[2],JomegaD[4]) \n",
    "    rate3_750=R3(JomegaD[0],JomegaD[2],JomegaD[4])\n",
    "     \n",
    "    Jw1LS2_600=LS2(p2x,measuredfreq)[0] # calculation of spectral density values at measured frequencies for LS2/LS3\n",
    "    Jw2LS2_600=LS2(p2x,measuredfreq)[1]\n",
    "    Jw3LS2_600=LS2(p2x,measuredfreq)[3]\n",
    "    \n",
    "    Jw1LS2_750=LS2(p2x,measuredfreq)[0] \n",
    "    Jw2LS2_750=LS2(p2x,measuredfreq)[2]\n",
    "    Jw3LS2_750=LS2(p2x,measuredfreq)[4] \n",
    "    \n",
    "    Jw1LS3_600=LS3(p3x,measuredfreq)[0]\n",
    "    Jw2LS3_600=LS3(p3x,measuredfreq)[1]\n",
    "    Jw3LS3_600=LS3(p3x,measuredfreq)[3]\n",
    "    \n",
    "    Jw1LS3_750=LS3(p3x,measuredfreq)[0]\n",
    "    Jw2LS3_750=LS3(p3x,measuredfreq)[2]\n",
    "    Jw3LS3_750=LS3(p3x,measuredfreq)[4]\n",
    "    \n",
    "    rate1LS2_600=R1(Jw1LS2_600,Jw2LS2_600,Jw3LS2_600) # rates from LS2/LS3\n",
    "    rate2LS2_600=R2(Jw1LS2_600,Jw2LS2_600,Jw3LS2_600)\n",
    "    rate3LS2_600=R3(Jw1LS2_600,Jw2LS2_600,Jw3LS2_600)\n",
    "    \n",
    "    rate1LS2_750=R1(Jw1LS2_750,Jw2LS2_750,Jw3LS2_750) \n",
    "    rate2LS2_750=R2(Jw1LS2_750,Jw2LS2_750,Jw3LS2_750)\n",
    "    rate3LS2_750=R3(Jw1LS2_750,Jw2LS2_750,Jw3LS2_750)\n",
    "    \n",
    "    rate1LS3_600=R1(Jw1LS3_600,Jw2LS3_600,Jw3LS3_600)\n",
    "    rate2LS3_600=R2(Jw1LS3_600,Jw2LS3_600,Jw3LS3_600)\n",
    "    rate3LS3_600=R3(Jw1LS3_600,Jw2LS3_600,Jw3LS3_600)\n",
    "    \n",
    "    rate1LS3_750=R1(Jw1LS3_750,Jw2LS3_750,Jw3LS3_750)\n",
    "    rate2LS3_750=R2(Jw1LS3_750,Jw2LS3_750,Jw3LS3_750)\n",
    "    rate3LS3_750=R3(Jw1LS3_750,Jw2LS3_750,Jw3LS3_750)\n",
    "    \n",
    "    ratesanalytical=[rate1_600,rate2_600,rate3_600,rate1_750,rate2_750,rate3_750] # rates directly from TCF\n",
    "    \n",
    "    ratesLS2=[rate1LS2_600,rate2LS2_600,rate3LS2_600,rate1LS2_750,rate2LS2_750,rate3LS2_750] \n",
    "    ratesLS3=[rate1LS3_600,rate2LS3_600,rate3LS3_600,rate1LS3_750,rate2LS3_750,rate3LS3_750] \n",
    "    \n",
    "    AIC_LS2 = CHIsq(ratesLS2,Rates1to3,Rates_err1to3) + 2*2 # CHIsqrt(Rmodel,Rnmr,Rerror)\n",
    "    AIC_LS3 = CHIsq(ratesLS3,Rates1to3,Rates_err1to3) + 3*2 # CHIsqrt(Rmodel,Rnmr,Rerror)\n",
    "    \n",
    "    print(ratesLS2,Rates1to3,Rates_err1to3,\"\\n\")\n",
    "    print(ratesLS3,Rates1to3,Rates_err1to3,\"\\n\")\n",
    "    \n",
    "    # JomegaD_stdv = - define \n",
    "    #\n",
    "    \n",
    "    stdvLS2 = STDV(JomegaD[0],JomegaD[1],JomegaD[3],JomegaD[2],JomegaD[4],Jw1LS2_600,Jw2LS2_600,Jw3LS2_600,Jw2LS2_750,Jw3LS2_750)\n",
    "    stdvLS3 = STDV(JomegaD[0],JomegaD[1],JomegaD[3],JomegaD[2],JomegaD[4],Jw1LS3_600,Jw2LS3_600,Jw3LS3_600,Jw2LS3_750,Jw3LS3_750)\n",
    "    \n",
    "    Jw0_ErrChi2 = ERRCHI2(result1.x[0],resultA.x[0],resultB.x[0],resultC.x[0],resultD.x[0],resultE.x[0],resultF.x[0],resultG.x[0],resultH.x[0])\n",
    "    JwD_600_ErrChi2 = ERRCHI2(result1.x[1],resultA.x[1],resultB.x[1],resultC.x[1],resultD.x[1],resultE.x[1],resultF.x[1],resultG.x[1],resultH.x[1])\n",
    "    JwD2_600_ErrChi2 = ERRCHI2(result1.x[2],resultA.x[2],resultB.x[2],resultC.x[2],resultD.x[2],resultE.x[2],resultF.x[2],resultG.x[2],resultH.x[2])\n",
    "    JwD_750_ErrChi2 = ERRCHI2(result1.x[3],resultA.x[3],resultB.x[3],resultC.x[3],resultD.x[3],resultE.x[3],resultF.x[3],resultG.x[3],resultH.x[3])\n",
    "    JwD2_750_ErrChi2 = ERRCHI2(result1.x[4],resultA.x[4],resultB.x[4],resultC.x[4],resultD.x[4],resultE.x[4],resultF.x[4],resultG.x[4],resultH.x[4])\n",
    "    \n",
    "    err_Jws = np.array([Jw0_ErrChi2,JwD_600_ErrChi2,JwD2_600_ErrChi2,JwD_750_ErrChi2,JwD2_750_ErrChi2]) \n",
    "    #print(stdvLS2, Jw0_ErrChi2)\n",
    "    \n",
    "    ### MONTE CARLO TO DEFINE PARAMETERS (S2, tauf) ERRORS, SAVE PARAMETERS TO THE FILES      \n",
    "    \n",
    "    #if AIC_LS2<=AIC_LS3:\n",
    "    if LSmodel[j] == 2:\n",
    "        LSns_MC = LS2ns_MC\n",
    "        stdvLS = stdvLS2\n",
    "        vGuess = [0.5,50]\n",
    "        #stdv = np.array([stdvLS2,stdvLS2,stdvLS2,stdvLS2,stdvLS2])/pico\n",
    "        errLSXfunc = errLS2func\n",
    "        errLSXnsfunc = errLS2nsfunc\n",
    "        boundsx = bounds2\n",
    "        p00 = p02\n",
    "    else:\n",
    "        LSns_MC = LS3ns_MC\n",
    "        stdvLS = stdvLS3\n",
    "        vGuess = [0.5,100,5000]\n",
    "        #stdv = np.array([stdvLS3,stdvLS3,stdvLS3,stdvLS3,stdvLS3])/pico\n",
    "        errLSXfunc = errLS3func\n",
    "        errLSXnsfunc = errLS3nsfunc\n",
    "        boundsx = bounds3\n",
    "        p00 = p03\n",
    "        \n",
    "    sErrorOld = stdvLS/pico\n",
    "    \n",
    "    #sError = np.mean(err_Jws)\n",
    "    sError = err_Jws\n",
    "    \n",
    "    #print(sErrorOld, sError)\n",
    "\n",
    "#################################    \n",
    "    nTrials = 4000\n",
    "    #print (\"MC Trials =\", nTrials)\n",
    "    aFitPars = np.array([])\n",
    "    \n",
    "\n",
    "    \n",
    "    for iTrial in range(nTrials):\n",
    "        xTrial = measuredfreq*pico\n",
    "        yGen = JomegaD/pico\n",
    "        yTrial = yGen + np.random.normal(scale=sError,size=np.size(yGen))\n",
    "\n",
    "        # We use a try/except clause to catch pathologies\n",
    "        try:                \n",
    "                vTrial, aCova = optimize.curve_fit(LSns_MC,xTrial,yTrial,vGuess)\n",
    "                #vTrial1 = optimize.least_squares(errLSXnsfunc, p00, bounds=boundsx, args=(measuredfreq*pico, yTrial)) # fit with LS2/LS3 function\n",
    "                #vTrial = vTrial1.x\n",
    "        except:\n",
    "            #dumdum=1\n",
    "            continue  # This moves us to the next loop without stacking.\n",
    "            \n",
    "        #here follows the syntax for stacking the trial onto the running sample:\n",
    "        if np.size(aFitPars) < 1:\n",
    "            aFitPars=np.copy(vTrial)\n",
    "            #print (vTrial)\n",
    "        else:\n",
    "            aFitPars = np.vstack(( aFitPars, vTrial ))\n",
    "            #print (vTrial)            \n",
    "            \n",
    "#     ax = plt.subplot(211)\n",
    "#     ax.hist(aFitPars[:,0],bins=50)\n",
    "    \n",
    "#     ax1 = plt.subplot(212)\n",
    "#     ax1.hist(aFitPars[:,1],bins=50, facecolor='orange')\n",
    "    \n",
    "    #print ('aFitPars',aFitPars)\n",
    "    S2_tauf_MC_std=np.array([float(np.median(aFitPars[:,0])), float(np.std(aFitPars[:,0])), \\\n",
    "                             float(np.median(aFitPars[:,1])), float(np.std(aFitPars[:,1]))])\n",
    "    \n",
    "    #if AIC_LS2<=AIC_LS3:\n",
    "    if LSmodel[j] == 2:\n",
    "        S2_tauf_MC_stdOnly=np.array([float(np.std(aFitPars[:,0])), float(np.std(aFitPars[:,1]))*pico])\n",
    "        \n",
    "        #print (\"std\", S2_tauf_MC_stdOnly)\n",
    "        p2x_min = p2x-S2_tauf_MC_stdOnly\n",
    "        p2x_max = p2x+S2_tauf_MC_stdOnly\n",
    "        #print('p2x: ',p2x)        \n",
    "        #print('p2x_min: ',p2x_min)\n",
    "        #print(p2x_max)\n",
    "        #test1 = LS2(p2x_min,frequency);\n",
    "        #print('LS2 test: ', test1)\n",
    "        \n",
    "    else:\n",
    "        S2_tauf_MC_stdOnly=np.array([float(np.std(aFitPars[:,0])), float(np.std(aFitPars[:,1]))*pico, float(np.std(aFitPars[:,2]))*pico])\n",
    "        #S2_tauf_MC_stdOnly=np.array([float(np.std(aFitPars[:,0])), float(np.std(aFitPars[:,1]))*pico, 0])\n",
    "\n",
    "        #print (\"std\", S2_tauf_MC_stdOnly)\n",
    "        p3x_min = p3x-S2_tauf_MC_stdOnly\n",
    "        p3x_max = p3x+S2_tauf_MC_stdOnly\n",
    "        #print('p3x: ',p3x)\n",
    "        #print('p3x_min: ',p3x_min)\n",
    "        #print('p3x_max: ',p3x_max)\n",
    "        #test1 = LS3(p3x_min,frequency);\n",
    "        #print('LS3 test: ', test1)\n",
    "    \n",
    "\n",
    "    \n",
    "    ### END MONTE CARLO ###\n",
    "\n",
    "    values=[rate1_600,rate2_600,rate3_600,rate1_750,rate2_750,rate3_750,\n",
    "            p2x[0],p2x[1],rate1LS2_600,rate2LS2_600,rate3LS2_600,rate1LS2_750,rate2LS2_750,rate3LS2_750,\n",
    "            Jw1LS2_600,Jw2LS2_600,Jw3LS2_600,Jw1LS2_750,Jw2LS2_750,Jw3LS2_750,\n",
    "            p3x[0],p3x[2],p3x[1],rate1LS3_600,rate2LS3_600,rate3LS3_600,rate1LS3_750,rate2LS3_750,rate3LS3_750,\n",
    "            Jw1LS3_600,Jw2LS3_600,Jw3LS3_600,Jw1LS3_750,Jw2LS3_750,Jw3LS3_750,AIC_LS2,AIC_LS3] # all results in one array\n",
    "    \n",
    "#   indices=[\"R1spec\",\"R2spec\",\"R3spec\", \n",
    "#          \"SLS2\",\"taufLS2\",\"R1LS2_600\",\"R2LS2_600\",\"R3LS2_600\",\"R1LS2_750\",\"R2LS2_750\",\"R3LS2_750\",\n",
    "#          \"Jw1LS2_600\",\"Jw2LS2_600\",\"Jw3LS2_600\",\"Jw1LS2_750\",\"Jw2LS2_750\",\"Jw3LS2_750\",\n",
    "#          \"SLS3\",\"taurLS3\",\"taufLS3\",\"R1LS3_600\",\"R2LS3_600\",\"R3LS3_600\",\"R1LS3_750\",\"R2LS3_750\",\"R3LS3_750\",\n",
    "#          \"Jw1LS3_600\",\"Jw2LS3_600\",\"Jw3LS3_600\",\"Jw1LS3_750\",\"Jw2LS3_750\",\"Jw3LS3_750\"]\n",
    " \n",
    "    \n",
    "    #if plotting:\n",
    "    output=pd.DataFrame(values,indices) # dataframe describing the output which will be written to the file\n",
    "    output.to_csv(outputpath+\"/params_\"+meth3ID,sep=\" \", header=False) # write values to file\n",
    "\n",
    "    j += 1    \n",
    "    # PLOTTING\n",
    "    \n",
    "    # Make a dictionary for latex formatting in the plot titles:\n",
    "    latex_title = {\"CBHB\": r\"-$C^{\\beta}H^{\\beta}$\",\n",
    "                   \"CDHD\": r\"-$C^{\\delta}H^{\\delta}$\",\n",
    "                   \"CEHE\": r\"-$C^{\\epsilon}H^{\\epsilon}$\",\n",
    "                   \"CD1HD1\": r\"-$C^{\\delta1}H^{\\delta1}$\",\n",
    "                   \"CD2HD2\": r\"-$C^{\\delta2}H^{\\delta2}$\",\n",
    "                   \"CG1HG1\": r\"-$C^{\\gamma1}H^{\\gamma1}$\",\n",
    "                   \"CG2HG2\": r\"-$C^{\\gamma2}H^{\\gamma2}$\"}\n",
    "\n",
    "    \n",
    "    if plotting:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        edge=0.2\n",
    "        ax = plt.subplot(111)\n",
    "        plt.subplots_adjust(bottom=edge, left=edge)\n",
    "        ax.tick_params(pad=10)\n",
    "        #plt.title(mutant[:3]+\" \"+mutant[-2:]+\" \"+meth3ID, fontsize=20)\n",
    "        plt.title(mutant[:3]+\" \"+mutant[4:]+\" \"+meth3ID.split(\"-\")[0]+latex_title[meth3ID.split(\"-\")[1]], fontsize=20)\n",
    "\n",
    "        #plt.plot(frequency, specfunc(frequency)/pico, label=\"FT of MD data fit\",c=\"r\") \n",
    "        plt.plot(frequency, LS2(p2x, frequency)/pico, c=\"b\", linestyle=\"--\", label=r'NMR LS2 fit ($S^\\mathrm{2}_\\mathrm{axis}$='+str(\"%.2f\" % round(p2x[0],2))+r', $\\tau_\\mathrm{R}$='+str(\"%.1f\" % round(taum/1000/pico,1))+r' ns, $\\tau_\\mathrm{f}$='+str(\"%.1f\" % round(p2x[1]/pico,1))+r' ps)')\n",
    "        \n",
    "        #if AIC_LS2<=AIC_LS3:\n",
    "        if LSmodel[j-1] == 2:\n",
    "            plt.fill_between(frequency,LS2(p2x_min,frequency)/pico,LS2(p2x_max,frequency)/pico,facecolor='lightgrey', interpolate=True, edgecolors=\"None\",label=\"Confidence interval (LS2)\")        \n",
    "        else:\n",
    "            plt.fill_between(frequency,LS3(p3x_min,frequency)/pico,LS3(p3x_max,frequency)/pico,facecolor='lightgrey', interpolate=True, edgecolors=\"None\",label=\"Confidence interval (LS3)\")        \n",
    "\n",
    "            \n",
    "        plt.plot(frequency, LS3(p3x, frequency)/pico, c=\"r\", linestyle=\"--\", label=r'NMR LS3 fit ($S^\\mathrm{2}_\\mathrm{axis}$='+str(\"%.2f\" % round(p3x[0],2))+r', $\\tau_\\mathrm{c}^\\mathrm{eff}$='+str(\"%.1f\" % round(p3.x[2]/1000,1))+r' ns, $\\tau_\\mathrm{f}$='+str(\"%.1f\" % round(p3.x[1],1))+r' ps)') # Plot of the data and the fit\n",
    "        plt.errorbar(measuredfreq, JomegaD/pico, yerr=err_Jws, c=\"k\", linestyle=\"None\", fmt='o', capsize = 4, label=\"NMR Jw's at measured frequencies\", ms=3)\n",
    "        plt.xlabel(r'$\\omega [s^{-1}]$')\n",
    "        plt.ylabel(r'$J[ps]$')\n",
    "        ax.xaxis.set_major_formatter(mtick.ScalarFormatter(useMathText=True))\n",
    "        ax.yaxis.set_major_formatter(mtick.ScalarFormatter(useMathText=True))\n",
    "        plt.xlim(-10**8,2*10**9)\n",
    "        plt.legend(numpoints=1, fontsize=8)\n",
    "        plt.savefig(outputpath+\"/spec_dens_\"+meth3ID+\".png\",dpi=600)\n",
    "        #plt.savefig(outputpath+\"/spec_dens_\"+meth3ID+\".pdf\",dpi=1200)\n",
    "        plt.close()\n",
    "\n",
    "            # Plot spectral density:\n",
    "    if subplots:\n",
    "        #fname = \"specdens_all.pdf\"\n",
    "        #edge=0.2\n",
    "        #ax = plt.subplot(111)\n",
    "        ax = plt.subplot(round(data1.shape[0]/2), 2, j)\n",
    "        #plt.subplots_adjust(bottom=edge, left=edge)\n",
    "        #plt.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.25, wspace=0.35)\n",
    "        plt.subplots_adjust(top=0.99, right=0.99)\n",
    "        ax.tick_params(pad=10)\n",
    "        \n",
    "        #ax.plot(measuredfreq, JomegaD/pico, \"rv\", label=\"NMR optimized Jw's at measured frequencies\", ms=8)\n",
    "        ax.plot(frequency, LS2(p2x, frequency)/pico, c=\"b\", linestyle=\"--\", label=r'NMR LS2 fit ($S^\\mathrm{2}_\\mathrm{axis}$='+str(\"%.2f\" % round(p2x[0],2))+r', $\\tau_\\mathrm{R}$='+str(\"%.1f\" % round(taum/1000/pico,1))+r' ns, $\\tau_\\mathrm{f}$='+str(\"%.1f\" % round(p2x[1]/pico,1))+r' ps)')\n",
    "        \n",
    "        #if AIC_LS2<=AIC_LS3:\n",
    "        if LSmodel[j-1] == 2:\n",
    "            ax.fill_between(frequency,LS2(p2x_min,frequency)/pico,LS2(p2x_max,frequency)/pico,facecolor='lightgrey', interpolate=True, edgecolors=\"None\",label=\"Confidence interval (LS2)\")        \n",
    "        else:\n",
    "            ax.fill_between(frequency,LS3(p3x_min,frequency)/pico,LS3(p3x_max,frequency)/pico,facecolor='lightgrey', interpolate=True, edgecolors=\"None\",label=\"Confidence interval (LS3)\")        \n",
    "\n",
    "        \n",
    "        ax.plot(frequency, LS3(p3x, frequency)/pico, c=\"r\", linestyle=\"--\", label=r'NMR LS3 fit ($S^\\mathrm{2}_\\mathrm{axis}$='+str(\"%.2f\" % round(p3x[0],2))+r', $\\tau_\\mathrm{c}^\\mathrm{eff}$='+str(\"%.1f\" % round(p3.x[2]/1000,1))+r' ns, $\\tau_\\mathrm{f}$='+str(\"%.1f\" % round(p3.x[1],1))+r' ps)') # Plot of the data and the fit\n",
    "        ax.errorbar(measuredfreq, JomegaD/pico, yerr=err_Jws, c=\"k\", linestyle=\"None\", fmt='o', capsize = 4, label=\"NMR Jw's at measured frequencies\", ms=3)\n",
    "\n",
    "        ax.set_xlabel(r'$\\omega [s^{-1}]$')\n",
    "        ax.set_ylabel(r'$J[ps]$')\n",
    "        #ax.set_title(\"CI2 WT \"+meth3ID, fontsize=20)\n",
    "        #ax.set_title(mutant[:3]+\" \"+mutant[-2:]+\" \"+meth3ID, fontsize=20)\n",
    "        plt.title(mutant[:3]+\" \"+mutant[4:]+\" \"+meth3ID.split(\"-\")[0]+latex_title[meth3ID.split(\"-\")[1]], fontsize=20)\n",
    "\n",
    "        ax.xaxis.set_major_formatter(mtick.ScalarFormatter(useMathText=True))\n",
    "        ax.yaxis.set_major_formatter(mtick.ScalarFormatter(useMathText=True))\n",
    "        plt.xlim(-10**8,2*10**9)\n",
    "        plt.legend(numpoints=1, fontsize=8, loc = 1)\n",
    "   \n",
    "        \n",
    "        #print (\"#\", j) \n",
    "    #with open(\"/Users/psz898/OneDrive/Documents/SCIENCE/UCPH/Reports/CI2_summary/ci2_nmr_relax_output/order_\"+mutant+\"_methyl_chi2.dat\", 'w+') as f:\n",
    "       \n",
    "        #order_new = pd.DataFrame([float(p2x[0])],index = [meth3ID]) # order parameter for this methyl group\n",
    "    #if AIC_LS2<=AIC_LS3:\n",
    "    #        order_new=pd.DataFrame([float(p2x[0])],index=[meth3ID]) # order parameter for this methyl group\n",
    "    #        print (j,\"\\t\",meth3ID,\"\\t\",\"S2\", \"%.2f\" % p2x[0],\"+/-\", \"%.3f\" % S2_tauf_MC_std[1],\"tau_f\", \"%1.2f\" % p2.x[1],\"+/-\", \"%.2f\" % S2_tauf_MC_std[3] ,\"LS2 AIC\", \"%.2f\" % AIC_LS2)\n",
    "    #        # add errors for S2\n",
    "    #        # add file with tauf and errors\n",
    "    #        # file with S2, err, tauf, err, LS2 AIC LS3 AIC LS_chosen AIC_chosen\n",
    "    #else:\n",
    "    #        order_new=pd.DataFrame([float(p3x[0])],index=[meth3ID])\n",
    "    #        print (j,\"\\t\",meth3ID,\"\\t\",\"S2\", \"%.2f\" % p3x[0],\"+/-\", \"%.3f\" % S2_tauf_MC_std[1],\"tau_f\", \"%1.2f\" % p3.x[1],\"+/-\", \"%.2f\" % S2_tauf_MC_std[3] ,\"LS3 AIC\", \"%.2f\" % AIC_LS3)\n",
    "    #order=order.append(order_new) # append order parameter to dataframe containing all order parameters\n",
    "    \n",
    "    order_new = pd.DataFrame(columns = [\"methylID_full\", \"S2_LS2\", \"AIC_LS2\", \"S2_LS3\", \"AIC_LS3\", \"LS\", \"AIC\", \"S2\", \"S2_er\", \"tauf\", \"tauf_er\"])\n",
    "  \n",
    "    #if AIC_LS2<=AIC_LS3:\n",
    "    if LSmodel[j-1] == 2:\n",
    "        order_new = order_new.append(pd.DataFrame({\"methylID_full\": meth3ID, \"S2_LS2\":[float(p2x[0])],\"AIC_LS2\": AIC_LS2, \n",
    "                                                       \"S2_LS3\":[float(p3x[0])],\"AIC_LS3\": AIC_LS3,\"LS\":\"LS2\",\"AIC\":AIC_LS2, \"S2\":[float(p2x[0])],\"S2_er\":[float(S2_tauf_MC_std[1])], \n",
    "                                                       \"tauf\":p2.x[1],\"tauf_er\": S2_tauf_MC_std[3]}, index = [0]), ignore_index = True, sort=False)\n",
    "        \n",
    "        print (j,\"\\t\",meth3ID,\"\\t\",\"S2\", \"%.2f\" % p2x[0],\"+/-\", \"%.3f\" % S2_tauf_MC_std[1],\"tau_f\", \"%1.2f\" % p2.x[1],\"+/-\", \"%.2f\" % S2_tauf_MC_std[3] ,\"LS2 AIC\", \"%.2f\" % AIC_LS2)\n",
    "\n",
    "    else:\n",
    "        order_new = order_new.append(pd.DataFrame({\"methylID_full\": meth3ID, \"S2_LS2\":[float(p2x[0])],\"AIC_LS2\": AIC_LS2, \n",
    "                                                       \"S2_LS3\":[float(p3x[0])],\"AIC_LS3\": AIC_LS3,\"LS\":\"LS3\",\"AIC\":AIC_LS3, \"S2\":[float(p3x[0])],\"S2_er\":[float(S2_tauf_MC_std[1])], \n",
    "                                                       \"tauf\":p3.x[1],\"tauf_er\": S2_tauf_MC_std[3]}, index = [0]), ignore_index = True, sort=False)\n",
    "        \n",
    "        print (j,\"\\t\",meth3ID,\"\\t\",\"S2\", \"%.2f\" % p3x[0],\"+/-\", \"%.3f\" % S2_tauf_MC_std[1],\"tau_f\", \"%1.2f\" % p3.x[1],\"+/-\", \"%.2f\" % S2_tauf_MC_std[3] ,\"LS3 AIC\", \"%.2f\" % AIC_LS3)\n",
    "\n",
    "        \n",
    "    order = order.append(order_new) # append order parameter to dataframe containing all order parameter\n",
    "\n",
    "order.to_csv(outputpath+\"/order_\"+mutant+\"_methyl.dat\",header=True,sep=\"\\t\", float_format='%5.3f') # write order parameter to file\n",
    "print (\"Printing the plots...\")\n",
    "\n",
    "if subplots:\n",
    "    #plt.savefig(outputpath+\"/spec_dens_\"+meth3ID+\".png\",dpi=600)\n",
    "    #plt.savefig(outputpath+\"/spec_dens_\"mutant[:3]+\" \"+mutant[-2:]+\".pdf\",dpi=1200)        \n",
    "    fig1.tight_layout(rect=[0, 0.03, 1, 0.96])\n",
    "    fig1.savefig(str(outputpath+\"/\"+mutant+\"_spec_dens.pdf\"), dpi = 1200, bbox_inches='tight') \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
